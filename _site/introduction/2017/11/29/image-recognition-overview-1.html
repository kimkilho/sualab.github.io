<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Page metadata --> 
  <!-- Reference: http://jovandeginste.github.io/2016/05/18/add-metadata-tags-to-jekyll-blog-posts.html -->
  <meta name="description" content="지난 번 글까지 해서 수아랩의 핵심 기술들 중 하나인 ‘딥러닝’에 대해 알아보았습니다. 오늘날 딥러닝 기술이 적용되고 있는 분야는 이미지 인식, 음성 인식, 자연어 처리 등 여러 가지가 있습니다. 오늘은 이러한 적용 분야들 중, 딥러닝의 위력을 가장 드라마틱하게 보여주고 있다고 할...">

  <meta property="og:site_name" content="Cognex Deep Learning Lab-KOR Research Blog">
  
  <meta property="og:title" content="이미지 인식 문제의 개요: PASCAL VOC Challenge를 중심으로 (1)">
  <meta property="og:type" content="article">
  <meta property="og:description" content="지난 번 글까지 해서 수아랩의 핵심 기술들 중 하나인 ‘딥러닝’에 대해 알아보았습니다. 오늘날 딥러닝 기술이 적용되고 있는 분야는 이미지 인식, 음성 인식, 자연어 처리 등 여러 가지가 있습니다. 오늘은 이러한 적용 분야들 중, 딥러닝의 위력을 가장 드라마틱하게 보여주고 있다고 할 수 있는 ‘이미지 인식’ 분야에서 다루는 문제들을 정의하고, 이들의 주요 목표가 무엇인지, 모델의 예측 결과를 어떤 척도로 평가하는지 등에 대하여 살펴보고자 합니다. 우선 이미지 인식 분야에 대한 이해를 완벽하게 가져간 후에, 여기에 적용되는 딥러닝 기술에 대하여 추후에 자세히 살펴보도록 하겠습니다.

"/>
  
  
  <meta property="article:published_time" content="2017-11-29T09:00:00+09:00">
  <meta property="article:author" content="http://github.sualab.io/about/">
  
  <meta property="og:url" content="http://github.sualab.io/introduction/2017/11/29/image-recognition-overview-1.html" />
  
  <meta itemprop="keywords" content="pascal voc,classification,detection,segmentation" />
  
  <meta property="article:tag" content="pascal voc">
  
  <meta property="article:tag" content="classification">
  
  <meta property="article:tag" content="detection">
  
  <meta property="article:tag" content="segmentation">
  
  
  
  <!-- end of Page metadata -->

  <title>이미지 인식 문제의 개요: PASCAL VOC Challenge를 중심으로 (1)</title>
  <meta name="description" content="지난 번 글까지 해서 수아랩의 핵심 기술들 중 하나인 ‘딥러닝’에 대해 알아보았습니다. 오늘날 딥러닝 기술이 적용되고 있는 분야는 이미지 인식, 음성 인식, 자연어 처리 등 여러 가지가 있습니다. 오늘은 이러한 적용 분야들 중, 딥러닝의 위력을 가장 드라마틱하게 보여주고 있다고 할...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://github.sualab.io/introduction/2017/11/29/image-recognition-overview-1.html">  <link rel="alternate" type="application/rss+xml" title="Cognex Deep Learning Lab-KOR Research Blog" href="/feed.xml">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

  <!-- Enabling line-breaking for MathJax equations -->
  <!-- @reference: https://stackoverflow.com/questions/29893923/how-to-make-formula-with-mathjax-responsive/29904718 -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
       "HTML-CSS": { linebreaks: { automatic: true } },
                SVG: { linebreaks: { automatic: true } }
                });
  </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110963421-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110963421-1');
</script>


  
</head>
<body><header class="site-header" role="banner">

<div class="wrapper">
  
  
	<div class="cognex-logo-div">
		<img class="cognex-logo-img" src="/assets/images/Cognex_logo.png" />
	</div>
	<div>
  	<a class="site-title" href="/">Cognex Deep Learning Lab-KOR Research Blog</a>
	</div>

  
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
        </svg></span>
      </label>

      <div class="trigger">
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
	<a class="page-link" href="/Introduction.html"> Introduction </a>
	<a class="page-link" href="/Practice.html"> Practice </a>
	<a class="page-link" href="/Development.html"> Development </a>
	<a class="page-link" href="/Review.html"> Review </a>
	<a class="page-link" href="/etc..html"> etc. </a>
  <a class="page-link" href="https://jobs.cognex.com/" target="_blank"> Jobs </a>
      </div>
    </nav>
  
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <!-- Look the author details up from the site config. -->

<!-- Post metadata -->
<!-- Reference: http://jovandeginste.github.io/2016/05/18/add-metadata-tags-to-jekyll-blog-posts.html -->

<article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">이미지 인식 문제의 개요: PASCAL VOC Challenge를 중심으로 (1)</h1>
    <p class="post-meta">
      <time datetime="2017-11-29T09:00:00+09:00" itemprop="datePublished">
        
        Nov 29, 2017
      </time>
       • 
        
          <span itemprop="category" itemscope itemtype="http://schema.org/Category"><a href="/Introduction.html">Introduction</a></span>
        
      
      
        • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name"><a href="https://github.com/kimkilho" target="_blank">김길호</a></span></span>
        <!-- Author metadata -->
        <meta itemprop="email" content="Kyle.Kim@cognex.com" />
        <meta itemprop="web" content="https://github.com/kimkilho" />
        <!-- end of Author metadata -->
      
      
         <br>Tags: pascal voc, classification, detection, segmentation
      
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>지난 번 글까지 해서 수아랩의 핵심 기술들 중 하나인 ‘딥러닝’에 대해 알아보았습니다. 오늘날 딥러닝 기술이 적용되고 있는 분야는 이미지 인식, 음성 인식, 자연어 처리 등 여러 가지가 있습니다. 오늘은 이러한 적용 분야들 중, 딥러닝의 위력을 가장 드라마틱하게 보여주고 있다고 할 수 있는 ‘이미지 인식’ 분야에서 다루는 문제들을 정의하고, 이들의 주요 목표가 무엇인지, 모델의 예측 결과를 어떤 척도로 평가하는지 등에 대하여 살펴보고자 합니다. 우선 이미지 인식 분야에 대한 이해를 완벽하게 가져간 후에, 여기에 적용되는 딥러닝 기술에 대하여 추후에 자세히 살펴보도록 하겠습니다.</p>

<ul>
  <li>본문의 플롯을 위해 작성한 <a href="https://github.com/sualab/sualab.github.io/blob/master/assets/notebooks/image-recognition-overview.ipynb" target="_blank">Python 코드</a>를 부록으로 함께 첨부하였습니다.</li>
</ul>

<h2 id="서론">서론</h2>

<p><strong>이미지 인식(image recognition)</strong> 문제에서는, 기계로 하여금 주어진 이미지 상에 포함되어 있는 대상이 <em>무엇인지</em>, 또한 <em>어느 위치에 있는지</em> 등을 파악하도록 하는 것을 주된 목표로 합니다. 예를 들어, 수아랩 기술 블로그를 오랫동안 보아 오셨다면 너무나도 친숙할 만한, 아래와 같은 이미지가 주어졌다고 합시다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/tree-image.png" target="_blank">
  <img class="large-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/tree-image.png" alt="인간이 받아들이는 나무 이미지" />
</a>
<span class="caption">인간이 받아들이는 나무 이미지</span></p>

<p>5살 남짓의 어린 아이조차도, 위 이미지를 관찰한 순간 그 안에 ‘나무’라는 대상이 포함되어 있다는 것을 불과 0.1초 내로 <em>빠르고 정확하게</em> 인식할 수 있습니다. 비단 나무뿐만 아니라, 어린 아이는 그 주변에 존재하는 다양한 대상들에 대해서도 큰 무리 없이 유사한 속도와 성능(?)으로 인식할 것이라고 쉽게 예상할 수 있습니다.</p>

<p>그러나 오늘날 과학 기술이 꽃을 피운 21세기에 접어들었음에도 불구하고, 이렇게 어린 아이조차도 쉽게 할 수 있는 이미지 인식이, 기계에게는 여전히 매우 어려운 일로 받아들여지고 있습니다. 지난 <a href="http://research.sualab.com/machine-learning/2017/09/04/what-is-machine-learning.html" target="_blank">&lt;머신러닝이란 무엇인가?&gt;</a> 글에서도 언급하였듯이, 기계는 이미지를 <strong>픽셀(pixel)</strong> 단위의 수치화된 형태로 받아들이며, 일반적으로 인간이 보고 이해할 수 있을만큼 큰 이미지는 매우 많은 수의 픽셀들로 구성되어 있습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/tree-image-pixels.svg" target="_blank">
  <img class="large-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/tree-image-pixels.svg" alt="기계가 받아들이는 나무 이미지: 수많은 픽셀을 통한 표현*&lt;br&gt;&lt;small&gt;(*주의: 격자 안의 하나의 정사각형의 크기는 실제 1픽셀보다는 크며, 설명을 돕기 위해 과장하였습니다.)&lt;/small&gt;" />
</a>
<span class="caption">기계가 받아들이는 나무 이미지: 수많은 픽셀을 통한 표현*<br /><small>(*주의: 격자 안의 하나의 정사각형의 크기는 실제 1픽셀보다는 크며, 설명을 돕기 위해 과장하였습니다.)</small></span></p>

<blockquote>
  <p>위 나무 이미지는, 실제로는 756x409(=309,204)개의 픽셀로 이루어져 있습니다.</p>
</blockquote>

<p>위와 같은 이미지를 보고 ‘나무’라는 추상적인 개념을 뽑아내는 작업에 있어, 인간의 경우 (아직 완전히 밝혀지지 않은 모종의 매커니즘에 의해) ‘선택적 주의 집중(selective attention)’ 및 ‘문맥(context)’에 기반한 ‘종합적 이해’ 등의 과정을 거치며, 이 작업을 <em>직관적으로</em> 빠른 속도로 정확하게 수행할 수 있습니다. 반면, 기계는 ‘선택적 주의 집중’ 능력이 없기 때문에 픽셀의 값을 빠짐없이 하나하나 다 살펴봐야 하므로 일단 이 과정에서 속도가 느려질 수밖에 없으며, 이렇게 읽어들인 픽셀로부터 어떻게 ‘문맥’ 정보를 추출하고, 또 이들을 어떻게 ‘종합하고 이해’하는 것이 최적인지도 알지 못하므로 그 성능 또한 인간에 한참 뒤떨어질 수밖에 없습니다.</p>

<h3 id="인간의-인식-성능을-좇기-위한-도전">인간의 인식 성능을 좇기 위한 도전</h3>

<p>이러한 상황에서, 기계의 이미지 인식 속도와 성능을 인간의 수준으로 끌어올리기 위한 가장 효과적인 방법은 ‘인간이 이미지를 인식하는 매커니즘을 밝혀내고, 이를 기계로 하여금 모방하도록 해 보자’는 것이라고 생각할 수 있습니다. 실제로, 이는 뇌 과학(brain science) 분야에서 주로 다루어지는 연구 주제입니다. 이를 위해서는 인간의 지능을 구성하는 지식 표현, 학습, 추론, 창작 등에 해당하는 인공지능 문제들이 모두 풀려야 가능할 것으로 보이니, 이 방향으로 가기에는 아직 갈 길이 한참 먼 것이 현실입니다.</p>

<p>이미지 인식 연구 초창기에 뇌 과학의 연구 성과를 마냥 기다릴 수만은 없었던 공학자들은, 인간의 인식 메커니즘을 그대로 모방하려는 시도 대신, 기존의 이미지 인식 문제의 범위를 좁혀서 좀 더 특수한 목적을 지니는 쉬운 형태의 문제로 치환하고 이들을 수학적 기법을 통해 해결하는 방법을 고안해 왔습니다. 예를 들어, 인간의 ‘선택적 주의 집중’ 및 ‘문맥 파악’ 능력에는 못 미치지만, 어떤 특수한 문제 해결에 효과적인 <strong>요인(feature)</strong>을 정의하여 사용하고, 이들을 ‘종합하고 이해’하도록 하기 위해 <strong>러닝 모델(learning model)</strong>과 <strong>러닝 알고리즘(learning algorithm)</strong>을 사용하여 이를 머신러닝 차원으로 해결하고자 하였습니다. 특수한 이미지 인식 문제로는 <em>얼굴 인식(face recognition)</em>, <em>필적 인식(handwriting recognition)</em> 등이 대표적입니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/face-recognition-examples.png" target="_blank">
  <img class="medium-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/face-recognition-examples.png" alt="특수한 이미지 인식 문제 예시: 얼굴 인식(FERET database)" />
</a>
<span class="caption">특수한 이미지 인식 문제 예시: 얼굴 인식(FERET database)</span></p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/mnist-handwriting-examples.png" target="_blank">
  <img class="small-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/mnist-handwriting-examples.png" alt="특수한 이미지 인식 문제 예시: 필적 인식(MNIST database)" />
</a>
<span class="caption">특수한 이미지 인식 문제 예시: 필적 인식(MNIST database)</span></p>

<p>초창기의 이러한 시도들을 통해 자신감을 얻은 공학자들은, 좀 더 과감한 도전을 하기 시작하였습니다. 인간이 일상 속에서 접할 수 있는 몇 가지 주요한 사물들을 인식하기 위한 시도를 시작한 것입니다. 이는, 기계의 이미지 인식 성능의 벤치마크(benchmark)로 삼을 수 있는 다양한 데이터셋이 등장한 데에서부터 출발하였습니다. 예를 들어, <em>CIFAR-10 dataset</em>은 일반적인 이미지 인식을 위한 가장 대표적인 벤치마크용 데이터셋으로, 32x32 크기의 작은 컬러 이미지 상에 10가지 사물 중 어떤 것이 포함되어 있는지를 단순 분류하는 문제를 제시하기 위해 만들어졌습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/cifar10-examples.png" target="_blank">
  <img class="large-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/cifar10-examples.png" alt="일반적인 이미지 인식 데이터셋 예시: CIFAR-10" />
</a>
<span class="caption">일반적인 이미지 인식 데이터셋 예시: CIFAR-10</span></p>

<h3 id="이미지-인식-문제의-정립-classification-detection-segmentation">이미지 인식 문제의 정립: Classification, Detection, Segmentation</h3>

<p>연구실 차원에서의 이런 올망졸망한(?) 벤치마크 데이터셋에서 출발하여, 그 후에는 1만 장 이상의 거대한 스케일의 이미지 데이터셋에 대하여 인식 성능을 겨루는 대회가 본격적으로 등장하였습니다. 초창기의 이미지 인식 대회 중 가장 대표적인 것이 <em>PASCAL VOC Challenge</em>입니다. 이 대회를 기점으로, 이미지 인식에서 다루는 문제들이 어느 정도 정형화되었다고 할 수 있습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/classification-detection-segmentation.png" target="_blank">
  <img class="large-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/classification-detection-segmentation.png" alt="PASCAL VOC Challenge 문제: Classification, Detection, Segmentation" />
</a>
<span class="caption">PASCAL VOC Challenge 문제: Classification, Detection, Segmentation</span></p>

<p>PASCAL VOC Challenge를 기준으로 볼 때, 이미지 인식 분야에서 다루는 주요 문제를 크게 3가지로 정리할 수 있습니다. <strong>Classification</strong>, <strong>Detection</strong>, <strong>Segmentation</strong>이 바로 그것입니다. 지금부터 이들 각각의 문제가 무엇인지 정의하고, 각 문제와 관련된 주요한 이슈는 무엇인지, 어떤 기준으로 예측 성능을 평가하는지 순으로 이야기해 보도록 하겠습니다.</p>

<h2 id="classification">Classification</h2>

<h3 id="문제-정의">문제 정의</h3>

<p>Classification 문제에서는, <em>주어진 이미지 안에 어느 특정한 클래스에 해당하는 사물이 포함되어 있는지 여부를 분류하는 모델을 만드는 것</em>을 주요 목표로 합니다. 여기에서 <strong>클래스(class)</strong>란, 분류 대상이 되는 카테고리 하나하나를 지칭합니다.</p>

<p>본격적인 Classification을 수행하기 전에, 반드시 관심의 대상이 되는 클래스들을 미리 정해놓고 작업을 시작해야 합니다. 예를 들어, PASCAL VOC Challenge에서는 총 20가지 클래스를 상정하고, 이에 대한 classification을 수행하도록 하였습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/pascal-voc-classes.png" target="_blank">
  <img class="full-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/pascal-voc-classes.png" alt="PASCAL VOC Challenge에서 다루는 20가지 클래스&lt;br&gt;&lt;small&gt;(좌측 절반 10개: 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',&lt;br&gt; 우측 절반 10개: 'dining table', 'dog', 'horse', 'motorbike', 'person', 'potted plant', 'sheep', 'sofa', 'train', 'TV/monitor')&lt;/small&gt;" />
</a>
<span class="caption">PASCAL VOC Challenge에서 다루는 20가지 클래스<br /><small>(좌측 절반 10개: ‘aeroplane’, ‘bicycle’, ‘bird’, ‘boat’, ‘bottle’, ‘bus’, ‘car’, ‘cat’, ‘chair’, ‘cow’,<br /> 우측 절반 10개: ‘dining table’, ‘dog’, ‘horse’, ‘motorbike’, ‘person’, ‘potted plant’, ‘sheep’, ‘sofa’, ‘train’, ‘TV/monitor’)</small></span></p>

<p>PASCAL VOC Challenge를 비롯한 대부분의 이미지 인식 대회의 Classification 문제에서는, 주어진 이미지 안에 특정 클래스의 사물이 존재할 ‘가능성’ 내지는 ‘믿음’을 나타내는 <strong>신뢰도 점수(confidence score)</strong>를 제출하도록 요구합니다. 즉, ‘주어진 이미지 안에 클래스 X의 사물이 있다’는 식의 단정적인 결론 대신, ‘주어진 이미지 안에 클래스 X의 사물이 존재할 가능성이 \(s_X\), 클래스 Y의 사물이 존재할 가능성이 \(s_Y\), 클래스 Z의 사물이 존재할 가능성이 \(s_Z\), …’ 식의 결과물을 제출하도록 요구하고, 이를 통해 추후 정답 여부 확인 시 해당 결과물에 대한 사후적인 해석의 여지를 두게 되는 것입니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/classification-model.svg" target="_blank">
  <img class="full-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/classification-model.svg" alt="Classification 문제&lt;br&gt;&lt;small&gt;(예시 이미지: VOC2009 데이터셋 - 2009_001984.jpg)&lt;/small&gt;" />
</a>
<span class="caption">Classification 문제<br /><small>(예시 이미지: VOC2009 데이터셋 - 2009_001984.jpg)</small></span></p>

<h4 id="신뢰도-점수에-대한-해석-방법">신뢰도 점수에 대한 해석 방법</h4>

<p>Classification 문제에서 분류의 대상이 되는 이미지에는 반드시 하나의 사물만이 포함되어 있거나, 또는 복수 개의 서로 다른 사물들이 포함되어 있을 수도 있습니다. 둘 중 어느 경우를 전제하느냐에 따라, 신뢰도 점수에 대한 최종적인 해석 방법이 달라집니다.</p>

<p>먼저 <em>모든 이미지가 반드시 하나의 사물만을 포함하도록</em> 전제되어 있는 경우를 생각해 봅시다. 이를 편의 상 ‘<em>단일 사물 분류</em>’ 문제라고 지칭하도록 하겠습니다. 이 경우, 전체 클래스에 대한 신뢰도 점수 중 가장 큰 신뢰도 점수를 갖는 클래스를 선정하여, ‘주어진 이미지 안에 해당 클래스가 포함되어 있을 것이다’고 결론지을 수 있습니다. 예를 들어, 아래와 같이 ‘고양이’를 담고 있는 이미지가 주어졌을 때, 전체 20가지 클래스에 대한 신뢰도 점수들을 비교하여 그 중 가장 큰 신뢰도 점수를 지니는 ‘cat’ 클래스를 선정하여 제시할 수 있습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/single-object-classification-confidence-scores.svg" target="_blank">
  <img class="large-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/single-object-classification-confidence-scores.svg" alt="단일 사물 분류 문제에서의 신뢰도 점수 해석&lt;br&gt;&lt;small&gt;(예시 이미지: VOC2008 데이터셋 - 2008_005977.jpg)&lt;/small&gt;" />
</a>
<span class="caption">단일 사물 분류 문제에서의 신뢰도 점수 해석<br /><small>(예시 이미지: VOC2008 데이터셋 - 2008_005977.jpg)</small></span></p>

<p>단일 사물 분류를 요구하는 데이터셋으로는 앞서 언급했던 MNIST, CIFAR-10 등이 있으며, 이들은 상대적으로 쉬운 문제로 취급됩니다.</p>

<p>반면, 이번에는 <em>이미지 상에 복수 개의 사물들이 포함되어 있을 수 있도록</em> 전제되어 있는 경우입니다. 이를 ‘<em>복수 사물 분류</em>’ 문제라고 지칭하도록 하겠습니다. 이 경우, 단순히 위와 같이 가장 큰 신뢰도 점수를 갖는 클래스 하나만을 선정하여 제시하는 것은 그다지 합리적인 결론이 아닐 것입니다.</p>

<p>이러한 문제 상황에서는 이미지 인식 대회마다 결론을 도출하는 방식이 조금씩 다르나, PASCAL VOC Challenge의 경우에는 각 클래스마다 <strong>문턱값(threshold)</strong>을 미리 설정해 놓고, 주어진 이미지의 <em>각 클래스 별 신뢰도 점수가 문턱값보다 <strong>큰</strong> 경우에 한하여 ‘주어진 이미지 안에 해당 클래스가 포함되어 있을 것이다’고 결론</em>짓도록 합니다. 예를 들어, 아래와 같이 ‘소’와 ‘사람’을 동시에 담고 있는 이미지가 주어졌을 때, 20가지 클래스 각각의 신뢰도 점수들을 조사하여, 이들 중 사전에 정한 문턱값보다 큰 신뢰도 점수를 지니는 ‘cow’와 ‘person’ 클래스를 선정하여 제시할 수 있습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/multiple-objects-classification-confidence-scores.svg" target="_blank">
  <img class="large-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/multiple-objects-classification-confidence-scores.svg" alt="복수 사물 분류 문제에서의 신뢰도 점수 해석&lt;br&gt;&lt;small&gt;(예시 이미지: VOC2010 데이터셋 - 2010_001692.jpg)&lt;/small&gt;" />
</a>
<span class="caption">복수 사물 분류 문제에서의 신뢰도 점수 해석<br /><small>(예시 이미지: VOC2010 데이터셋 - 2010_001692.jpg)</small></span></p>

<blockquote>
  <p>그렇다면, 각 클래스의 문턱값은 어떻게 결정해야 할까요? 이는 어느 평가 척도를 사용하여 평가할지의 문제와 같이 엮어 고민해야 하는 문제입니다.</p>
</blockquote>

<p>복수 사물 분류 문제가 아무래도 현실 상황에 좀 더 부합한다고 할 수 있으며, 상대적으로 좀 더 어려운 문제로 취급됩니다. PASCAL VOC Challenge, ILSVRC(ImageNet Large Scale Visual Recognition Challenge) 등 주요한 이미지 인식 대회에서 이를 채택하고 있습니다.</p>

<h3 id="평가-척도">평가 척도</h3>

<h4 id="정확도accuracy">정확도(accuracy)</h4>

<p>어떤 모델의 Classification 성능을 평가하고자 할 때, 다양한 종류의 <strong>평가 척도(evaluation measure)</strong> 중 하나 혹은 여러 개를 선정하여 사용할 수 있습니다. 일반적으로 가장 쉽게 떠올릴 수 있는 척도로 <strong>정확도(accuracy)</strong>가 있습니다. Classification 문제에서의 정확도는 일반적으로, <em>테스트를 위해 주어진 전체 이미지 수 대비, 분류 모델이 올바르게 분류한 이미지 수</em>로 정의합니다.</p>

<p>\begin{equation}
\text{정확도} = \frac{\text{올바르게 분류한 이미지 수}} {\text{전체 이미지 수}}
\end{equation}</p>

<p>단일 사물 분류 문제에서는,  위에서 정의된 정확도를 평가 척도로 즉각 사용하여도 크게 문제가 없습니다. 예를 들어, 아래와 같이 전체 테스트용 이미지가 10개 있었다고 할 때, 분류 모델이 이들 중 7개를 올바르게 예측했다면, 정확도는 \(7 / 10 = 0.7\)(\(70\%\))이 됩니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/accuracy-example.svg" target="_blank">
  <img class="large-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/accuracy-example.svg" alt="단일 사물 분류 문제에서의 정확도 계산 예시" />
</a>
<span class="caption">단일 사물 분류 문제에서의 정확도 계산 예시</span></p>

<h4 id="정밀도precision와-재현율recall">정밀도(precision)와 재현율(recall)</h4>

<p>그러나, 복수 사물 분류 문제에서는, 위의 정확도를 그대로 사용하기 곤란해지는 상황이 발생합니다. 이 때문에, 정확도 대신 <strong>정밀도(precision)</strong> 및 <strong>재현율(recall)</strong> 등의 평가 척도를 사용합니다. 정밀도와 재현율은 하나의 클래스에 대하여 (다른 클래스와는 독립적으로) 매겨지는 평가 척도입니다.</p>

<p>Classification 문제에서의 어느 특정 클래스 \(c\)의 정밀도는, <em>분류 모델이 \(c\)일 것으로 예측한 이미지 수 대비, 분류 모델이 올바르게 분류한 클래스 \(c\) 이미지 수</em>로 정의합니다. 한편, 클래스 \(c\)의 재현율은, <em>전체 클래스 \(c\) 이미지 수 대비, 분류 모델이 올바르게 분류한 클래스 \(c\) 이미지 수</em>로 정의합니다.</p>

<p>\begin{equation}
\text{클래스 c의 정밀도} = \frac{\text{올바르게 분류한 클래스 c 이미지 수}} {\text{클래스 c일 것으로 예측한 이미지 수}}
\end{equation}</p>

<p>\begin{equation}
\text{클래스 c의 재현율} = \frac{\text{올바르게 분류한 클래스 c 이미지 수}} {\text{전체 클래스 c 이미지 수}}
\end{equation}</p>

<p>각 클래스에 대한 정밀도 및 재현율을 계산한 뒤, 이들 전체의 대표값(representative value)을 취하고, 이를 최종적인 평가 척도로 삼을 수 있습니다. 구체적으로, 전체 \(C\)개 클래스에 대한 평균 정밀도 및 평균 재현율을 계산하고자 한다면, 아래와 같은 공식을 사용할 수 있습니다(이 때, ‘클래스 \(c\) 이미지’란 클래스 \(c\)에 해당하는 사물을 포함하고 있는 이미지를 지칭합니다).</p>

<p>\begin{equation}
\text{평균 정밀도} = \frac{1}{C} \sum_{c=1}^{C} \text{(클래스 c의 정밀도)}
\end{equation}</p>

<p>\begin{equation}
\text{평균 재현율} = \frac{1}{C} \sum_{c=1}^{C} \text{(클래스 c의 재현율)}
\end{equation}</p>

<blockquote>
  <p>총으로 사냥을 하는 것에 비유하자면, 일단 발사한 탄환 하나마다 사냥감 하나씩을 반드시 놓치지 않고 맞추도록 하고자 한다면, 정밀도를 높이는 방향으로 전략을 짜야 합니다. 반면, ‘헛방’이 많이 나도 좋으니 어떻게든 자기 주변에 있는 모든 사냥감을 맞추는 것이 목표라면, 재현율을 높이는 방향으로 전략을 짜야 합니다.</p>
</blockquote>

<p>평균 정밀도를 계산하는 구체적인 과정을 보면, 아래 그림과 같이 원본 테스트 이미지들을 모델이 예측한 클래스를 기준으로 나눈 후, 각각에 대하여 정밀도를 따로 계산한 뒤, 이렇게 얻어진 클래스 별 정밀도의 평균을 계산합니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/precision-per-class-example.svg" target="_blank">
  <img class="large-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/precision-per-class-example.svg" alt="복수 사물 분류 문제에서의 클래스 별 정밀도 계산 예시&lt;br&gt;&lt;small&gt;(그림에 제시된 3개의 클래스에 대한 전체 평균 정밀도는 $$(0.4+0.6+0.4)/3 = 0.47(47\%)$$)&lt;/small&gt;" />
</a>
<span class="caption">복수 사물 분류 문제에서의 클래스 별 정밀도 계산 예시<br /><small>(그림에 제시된 3개의 클래스에 대한 전체 평균 정밀도는 \((0.4+0.6+0.4)/3 = 0.47(47\%)\))</small></span></p>

<p>다음으로 평균 재현율을 계산하는 구체적인 과정을 보면, 아래 그림과 같이 원본 테스트 이미지들을 실제 클래스를 기준으로 나눈 후, 각 클래스에 대하여 재현율을 따로 계산한 뒤, 이렇게 얻어진 클래스 별 재현율의 평균을 계산합니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/recall-per-class-example.svg" target="_blank">
  <img class="large-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/recall-per-class-example.svg" alt="복수 사물 분류 문제에서의 클래스 별 재현율 계산 예시&lt;br&gt;&lt;small&gt;(그림에 제시된 3개의 클래스에 대한 전체 평균 재현율은 $$(0.6+1.0+0.8)/3 = 0.8(80\%)$$)&lt;/small&gt;" />
</a>
<span class="caption">복수 사물 분류 문제에서의 클래스 별 재현율 계산 예시<br /><small>(그림에 제시된 3개의 클래스에 대한 전체 평균 재현율은 \((0.6+1.0+0.8)/3 = 0.8(80\%)\))</small></span></p>

<h4 id="신뢰도-점수의-문턱값에-따른-평가-척도-수치의-변화-가능성">신뢰도 점수의 문턱값에 따른 평가 척도 수치의 변화 가능성</h4>

<p>복수 사물 분류 문제의 경우, 각 클래스 별로 신뢰도 점수에 대한 문턱값을 어떻게 결정해야 하는지에 대한 이슈가 여전히 남아 있습니다. 이해를 돕기 위해, ‘car’ 클래스에 대한 분류 모델의 신뢰도 점수가 주어졌을 때, 특정 문턱값에 따라 결론을 내리는 상황을 살펴보도록 하겠습니다. 이 때, 편의 상 주어진 이미지를 ‘car’ 클래스로 예측하지 <em>않은</em> 경우를 not ‘car’ 클래스라고 지칭하도록 하겠습니다.</p>

<p>먼저, (1) <em>‘car’ 클래스의 문턱값을 높게 잡을수록, 분류 모델이 ‘car’ 클래스로 예측하게 되는 이미지의 개수가 감소</em>합니다. 이렇게 되면, 신뢰도 점수가 확실하게 높은 이미지에 대해서만 ‘car’ 클래스로 예측하게 되므로 <em>정밀도가 상승</em>하나, 반대로 실제 존재하는 많은 수의 ‘car’ 이미지들을 놓치게 되므로 <em>재현율은 하락</em>합니다.</p>

<p>반면에 (2) <em>‘car’ 클래스의 문턱값을 낮게 잡을수록, 분류 모델이 ‘car’ 클래스로 예측하게 되는 이미지의 개수가 증가</em>합니다. 이렇게 되면, 신뢰도 점수가 낮은 이미지들까지 공격적으로 ‘car’ 클래스로 예측하게 되므로 <em>재현율이 상승</em>하나, 반대로 많은 수의 not ‘car’ 이미지들마저 모조리 ‘car’ 클래스로 예측하게 되므로 <em>정밀도는 하락</em>합니다.</p>

<p>(1)과 (2)의 상황에서 확인할 수 있듯이, <em>정밀도와 재현율 간에는 서로 약한 trade-off 관계가 존재</em>합니다. 좀 더 구체적으로 ‘car’ 클래스에 대하여, 테스트 이미지들에 대한 분류 모델의 신뢰도 점수가 계산된 상황에서, 문턱값의 변화에 따라 모델의 예측 결과 및 실제 정답 여부를 아래 그림과 같이 나타냈습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/threshold-to-classification-results.svg" target="_blank">
  <img class="full-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/threshold-to-classification-results.svg" alt="'car' 클래스의 문턱값에 따른, 정밀도 및 재현율 결과 변화 표&lt;br&gt;&lt;small&gt;(정밀도 n/a의 경우, 클래스 $$c$$로 예측한 이미지 수가 0개이므로 계산이 불가함을 나타냄)&lt;/small&gt;" />
</a>
<span class="caption">‘car’ 클래스의 문턱값에 따른, 정밀도 및 재현율 결과 변화 표<br /><small>(정밀도 n/a의 경우, 클래스 \(c\)로 예측한 이미지 수가 0개이므로 계산이 불가함을 나타냄)</small></span></p>

<p>위 그림에서는 편의 상 문턱값을 \(1.0\) 간격으로 조정하면서 정밀도 및 재현율을 측정한 것인데, 문턱값의 조정 간격을 더 짧게 하고 정밀도와 재현율을 측정하면 아래와 같은 형태의 플롯을 얻을 수 있습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/precision-recall-to-threshold-plot.svg" target="_blank">
  <img class="medium-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/precision-recall-to-threshold-plot.svg" alt="'car' 클래스의 문턱값에 따른, 정밀도 및 재현율 결과 변화 플롯" />
</a>
<span class="caption">‘car’ 클래스의 문턱값에 따른, 정밀도 및 재현율 결과 변화 플롯</span></p>

<p>위 플롯에서, 정밀도 혹은 재현율이 변화하는 지점만을 포착하여, 이들 지점에서의 \((재현율, 정밀도)\)를 아래 그림과 같이 2차원 평면 상에 나타내는 것이 더 일반적인 표현 방법에 해당합니다. 이를 <strong>정밀도-재현율 곡선(precision-recall curve)</strong>이라고 부릅니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://github.sualab.io/assets/images/image-recognition-overview-1/precision-recall-curve-plot.svg" target="_blank">
  <img class="medium-image" src="http://github.sualab.io/assets/images/image-recognition-overview-1/precision-recall-curve-plot.svg" alt="'car' 클래스의 문턱값에 따른, 정밀도-재현율 곡선 플롯" />
</a>
<span class="caption">‘car’ 클래스의 문턱값에 따른, 정밀도-재현율 곡선 플롯</span></p>

<p>위의 사례에서는, ‘car’ 클래스의 문턱값을 약 \(2.3\) 정도로 설정했을 때, 정밀도 및 재현율 모두 \(0.8\)로 적당히 높은 수치를 기록했습니다. 아마도 여러분들께서는 위와 같이 문턱값을 조정하면서 테스트 이미지들에 대한 채점 결과를 관찰하여, 높은 수치의 정밀도 혹은 재현율을 발휘하는 문턱값을 결정하면 될 것 같다는 충동이 들 것입니다.</p>

<p>그런데, 사실 이런 방식으로 최적의 문턱값을 결정하여 최종 성능을 뽑아내면, 그 결과는 현재 가지고 있는 테스트 이미지들에 한해서만 지나치게 ‘낙관적인(optimistic)’ 결과가 되어 버립니다. 즉, 새로운 테스트 이미지가 들어오는 상황에서 발휘할 수 있는 ‘일반적인 성능’이라고 담보하기 어려워지는 것입니다.</p>

<blockquote>
  <p>이는 마치 시험 시작 직전에 시험 출제 문제를 1분 정도 슬쩍 컨닝한 뒤 시험을 보는 것과 같은 행동입니다.</p>
</blockquote>

<p>이러한 맹점을 보완하고자 대부분의 이미지 인식 대회에서는, 문턱값을 특정 값으로 한정시킨 상황에서의 성능 척도만을 보는 것이 아니라, 문턱값이 존재할 수 있는 전체 범위 내에서의 정밀도 및 재현율들을 계산하고, 이들의 대푯값을 계산하는 방법을 채택하고 있습니다.</p>

<p>예를 들어, PASCAL VOC Challenge에서는 <strong>평균 정밀도(average precision)</strong>라는 평가 척도를 사용합니다. 평균 정밀도는, 각 문턱값에서 얻어지는 정밀도를, (이전 문턱값에서와 비교한)재현율의 증가량으로 곱한 것들의 총합으로 정의되며, 단순하게 생각하면 <em>정밀도-재현율 곡선과 재현율 축 사이의 넓이</em>에 해당합니다.</p>

<p>\begin{equation}
\text{평균 정밀도} = \sum_t (R_t - R_{t-1}) \cdot P_t
\end{equation}</p>

<h3 id="의의">의의</h3>

<p>Classification 문제는, 이어질 Detection 및 Segmentation 문제를 향한 출발점이라고 할 수 있습니다. Detection 및 Segmentation 문제 해결을 위해서는 특정 클래스에 해당하는 사물이 이미지 상의 어느 곳에 위치하는지에 대한 정보를 파악해야 하는데, 이를 위해서는 우선 그러한 사물이 이미지 상에 존재하는지 여부가 반드시 먼저 파악되어야 하기 때문입니다.</p>

<p>이러한 경향 때문에, Classification 문제에서 우수한 성능을 발휘했던 모델을 Detection 또는 Segmentation을 위한 구조로 변형하여 사용할 경우, 그 역시 상대적으로 우수한 성능을 발휘하는 경향이 있습니다.</p>

<p><a href="/introduction/2017/11/29/image-recognition-overview-1.html/../image-recognition-overview-2.html">(다음 포스팅 보기)</a></p>

  </div>

</article>

      </div>
    </main><footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Cognex Deep Learning Lab-KOR Research Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Cognex Deep Learning Lab-KOR Research Blog
            
            </li>
            
            <li><a href="https://www.cognex.co.kr/" target="_blank">https://www.cognex.co.kr/</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          

          
          
          <li>
            <a href="https://facebook.com/cognexcorp" target="_blank"><i class="fa fa-facebook"></i> <span class="username">cognexcorp</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Cognex Deep Learning Lab-KOR research blog: covers subjects regarding machine learning, computer vision, high-performance computing, and so on.
</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
