<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Page metadata --> 
  <!-- Reference: http://jovandeginste.github.io/2016/05/18/add-metadata-tags-to-jekyll-blog-posts.html -->
  <meta name="description" content="안녕하세요, 오랜만에 포스팅합니다. 이전 글인 Classification 문제에 이어 딥러닝을 적용하여 Detection 문제를 해결한 사례를 앞선 포스팅과 마찬가지로 Tensorflow 구현 코드와 함께 소개해드리겠습니다. 이미 많은 포스팅에서 Detection에 대한 설명과 그...">

  <meta property="og:site_name" content="Cognex Deep Learning Lab-KOR Research Blog">
  
  <meta property="og:title" content="이미지 Detection 문제와 딥러닝: YOLOv2로 얼굴인식하기">
  <meta property="og:type" content="article">
  <meta property="og:description" content="안녕하세요, 오랜만에 포스팅합니다. 이전 글인 Classification 문제에 이어 딥러닝을 적용하여 Detection 문제를 해결한 사례를 앞선 포스팅과 마찬가지로 Tensorflow 구현 코드와 함께 소개해드리겠습니다. 이미 많은 포스팅에서 Detection에 대한 설명과 그 중 한 방법론인 YOLO(You Only Look Once)의 개념 및 특징에 대해 훌륭한 설명이 많기 때문에 같은 설명을 반복하기 보다 개념적인 설명은 조금 뒤로하고 실제 구현 코드와 이를 뒷받침하는 설명을 중심으로 진행하도록 하겠습니다.

"/>
  
  
  <meta property="article:published_time" content="2018-05-14T09:00:00+09:00">
  <meta property="article:author" content="http://localhost:4000/about/">
  
  <meta property="og:url" content="http://localhost:4000/practice/2018/05/14/image-detection-deep-learning.html" />
  
  <meta itemprop="keywords" content="detection,yolov2,tensorflow" />
  
  <meta property="article:tag" content="detection">
  
  <meta property="article:tag" content="yolov2">
  
  <meta property="article:tag" content="tensorflow">
  
  
  
  <!-- end of Page metadata -->

  <title>이미지 Detection 문제와 딥러닝: YOLOv2로 얼굴인식하기</title>
  <meta name="description" content="안녕하세요, 오랜만에 포스팅합니다. 이전 글인 Classification 문제에 이어 딥러닝을 적용하여 Detection 문제를 해결한 사례를 앞선 포스팅과 마찬가지로 Tensorflow 구현 코드와 함께 소개해드리겠습니다. 이미 많은 포스팅에서 Detection에 대한 설명과 그...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/practice/2018/05/14/image-detection-deep-learning.html">  <link rel="alternate" type="application/rss+xml" title="Cognex Deep Learning Lab-KOR Research Blog" href="/feed.xml">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

  <!-- Enabling line-breaking for MathJax equations -->
  <!-- @reference: https://stackoverflow.com/questions/29893923/how-to-make-formula-with-mathjax-responsive/29904718 -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
       "HTML-CSS": { linebreaks: { automatic: true } },
                SVG: { linebreaks: { automatic: true } }
                });
  </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  
</head>
<body><header class="site-header" role="banner">

<div class="wrapper">
  
  
	<div class="cognex-logo-div">
		<img class="cognex-logo-img" src="/assets/images/Cognex_logo.png" />
	</div>
	<div>
  	<a class="site-title" href="/">Cognex Deep Learning Lab-KOR Research Blog</a>
	</div>

  
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
      <label for="nav-trigger">
        <span class="menu-icon">
        <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
        </svg></span>
      </label>

      <div class="trigger">
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
	<a class="page-link" href="/Introduction.html"> Introduction </a>
	<a class="page-link" href="/Practice.html"> Practice </a>
	<a class="page-link" href="/Development.html"> Development </a>
	<a class="page-link" href="/Review.html"> Review </a>
	<a class="page-link" href="/etc..html"> etc. </a>
  <a class="page-link" href="https://jobs.cognex.com/" target="_blank"> Jobs </a>
      </div>
    </nav>
  
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <!-- Look the author details up from the site config. -->

<!-- Post metadata -->
<!-- Reference: http://jovandeginste.github.io/2016/05/18/add-metadata-tags-to-jekyll-blog-posts.html -->

<article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">이미지 Detection 문제와 딥러닝: YOLOv2로 얼굴인식하기</h1>
    <p class="post-meta">
      <time datetime="2018-05-14T09:00:00+09:00" itemprop="datePublished">
        
        May 14, 2018
      </time>
       • 
        
          <span itemprop="category" itemscope itemtype="http://schema.org/Category"><a href="/Practice.html">Practice</a></span>
        
      
      
        • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name"><a href="https://github.com/JongsooKeum" target="_blank">금종수</a></span></span>
        <!-- Author metadata -->
        <meta itemprop="email" content="Jongsoo.Keum@cognex.com" />
        <meta itemprop="web" content="https://github.com/JongsooKeum" />
        <!-- end of Author metadata -->
      
      
         <br>Tags: detection, yolov2, tensorflow
      
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>안녕하세요, 오랜만에 포스팅합니다. 이전 글인 Classification 문제에 이어 딥러닝을 적용하여 Detection 문제를 해결한 사례를 앞선 포스팅과 마찬가지로 <strong>Tensorflow</strong> 구현 코드와 함께 소개해드리겠습니다. 이미 많은 포스팅에서 <strong>Detection</strong>에 대한 설명과 그 중 한 방법론인 <strong>YOLO(You Only Look Once)</strong>의 개념 및 특징에 대해 훌륭한 설명이 많기 때문에 같은 설명을 반복하기 보다 개념적인 설명은 조금 뒤로하고 실제 구현 코드와 이를 뒷받침하는 설명을 중심으로 진행하도록 하겠습니다.</p>

<ul>
  <li><strong>다음과 같은 사항을 알고계시면 더 이해하기 쉽습니다.</strong>
    <ul>
      <li>딥러닝에 대한 전반적인 이해</li>
      <li>Python 언어 및 TensorFlow 프레임워크에 대한 이해</li>
    </ul>
  </li>
  <li>이번 글에서 구현한 YOLOv2의 경우, 논문에서 명시된 것처럼 ImageNet challenge 데이터셋으로 학습한 pre-trained model을 사용하지 않고, 학습방법을 단순화하여 성능이 논문과 상이할 가능성이 있습니다.</li>
  <li>이번 글에서는 과거 Classification 구현체와 마찬가지로 데이터셋(data set), 성능 평가(performance evaluation), 러닝 모델(learning model), 러닝 알고리즘(leaning algorithm) 4가지 요소를 나눠 구현하였으며, 중복을 피하기 위해 다르게 구현한 부분 위주로 설명합니다.
    <ul>
      <li>전체 구현체 코드는 <a href="https://github.com/sualab/object-detection-yolov2" target="_blank">수아랩의 GitHub 저장소</a>에서 자유롭게 확인하실 수 있습니다.</li>
      <li>본 글에서 사용한 얼굴인식 데이터셋은 이곳에서 다운로드 받으실 수 있으며, 저장소에 있는 스크립트(ellipsis_to_rectangle.py)를 참고하여 일반적인 Detection 문제에서 사용되는 Rectangle 형태의 annotation으로 변환하실 수 있습니다.</li>
      <li>제가 변환한 데이터셋은 <a href="https://drive.google.com/file/d/1qV4YSzvvTQ7rSi3iS2swkbA56QO-bbs8/view?usp=sharing" target="_blank">여기</a>서 받을 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h2 id="서론">서론</h2>

<p><a href="http://localhost:4000/computer-vision/2017/11/29/image-recognition-overview-1.html" target="_blank">이미지 인식 문제의 개요: PASCAL VOC Challenge를 중심으로</a>에서 언급한 바와 같이, <strong>PASCAL VOC challenge</strong>에서 중요하게 다루는 3가지 이미지 인식 문제 중 Classification에 이어서 <strong>Detection</strong>기술로 해결할 수 있는 간단한 사례를 소개하고, 이를 딥러닝 기술 중 많은 분들이 접해본 <strong>YOLO</strong>계열 기술을 통해 해결하는 과정을 설명드리겠습니다.</p>

<p>앞서 말씀드린 것과 같이 이번 포스팅은 개념적인 설명부터 시작하면 지나치게 글이 길어지고 집중도가 떨어질 것 같아 (1) 딥러닝 및 머신러닝에 대한 어느정도의 이해와, (2) Python 언어 및 TensorFlow 프레임워크에 대한 이해, 그리고 (3) YOLO계열 Detection 알고리즘에 대한 전반적인 이해를 알고 있다는 전제하에 글을 쓰겠습니다. 글을 읽다가 이해가 안되는 부분이 있다면 다른곳에 좋은 글이 많이 있으니 숙지하신 후 읽어보시길 권장드립니다.</p>

<p>본 포스팅에서 다룰 Detection문제로 이미 앞서 소개했고 많은 분들에게 알려진 PASCAL VOC Challenge 혹은 MS COCO Challenge 데이터셋으로 소개해드리려 했으나, 이들 데이터셋은 상당히 방대하고 지나치게 학습시간이 오래걸려 적합하지 않다고 판단하였습니다. 이에 실용적이며 간단하고 쉽게 확장이 가능한 <strong>얼굴 인식</strong> 데이터셋을 이용하여 문제를 단순화하여 진행하려고 합니다.</p>

<p><strong>얼굴 인식</strong> 문제를 해결하기 위한 딥러닝 알고리즘으로는 <strong>YOLO</strong>계열의 두번째 버전인 <strong>YOLOv2</strong>(<strong>YOLO9000</strong>)를 채택하였습니다. YOLO 모델의 경우 조금 시간이 지난 모델이긴 하지만, 속도면에서 요즘 모델과 비교해도 여전히 빠르며 성능도 여전히 준수한 편이며 직관적이기 때문에 이해하고 적용하는 데 <strong>R-CNN</strong>계열 혹은 <strong>SSD(Single Shot Detector)</strong>보다 나을 것이라 판단하였습니다.</p>

<p>YOLOv2 구현체는 앞선 <a href="http://localhost:4000/machine-learning/computer-vision/2018/01/17/image-classification-deep-learning.html" target="_blank">Classification 문제</a>와 같이 데이터셋(data set), 성능 평가(performance evaluation), 러닝 모델(learning model), 러닝 알고리즘(leaning algorithm) 4가지 요소를 중심으로 작성하였으며  이전 포스팅과 겹치지 않은 부분 위주로 소개해드리겠습니다.</p>

<h2 id="1-데이터셋-얼굴인식-face-detection">(1) 데이터셋: 얼굴인식 (Face Detection)</h2>

<p>얼굴인식 문제를 위해 사용한 데이터셋은 <a href="http://vis-www.cs.umass.edu/fddb/" target="_blank">FDDB: Face Detection Data Set and Benchmark(FDDB)</a>에서 가져왔습니다. 데이터셋의 원본 annotation의 경우 다음 <a href="http://vis-www.cs.umass.edu/fddb/samples/" target="_blank">샘플 예제</a>와 같이 타원형으로 annotation이 되어있기 때문에 일반적인 Detection annotation과 상이합니다. 이를 YOLO 모델에 쉽게 적용하기 위해서는 Rectangle형태로 변환해주는 것이 좋기 때문에 먼저 이 변환작업을 해주는 것을 추천드립니다.</p>

<p>Annotation 표현 방법은 무수히 많지만, 이번 포스팅 예제에서는 다음과 같은 형식으로 진행하도록 하겠습니다.</p>
<ul>
  <li>이미지마다 매칭되는 <strong>anno 확장자</strong> 파일 생성합니다. ex) sample1.png &lt;–&gt; sample1.anno</li>
  <li>anno 파일은 <strong>json 형식</strong>으로, 이름은 클래스 종류를 나타내고, 값은 array 형식으로 [x_min, y_min, x_max, y_max] 좌표 값을 가지고 있습니다. ex) 한 이미지에 얼굴 객체가 두개 있다면, { “face” : [ [20, 40, 78, 100], [150, 40, 170, 70] ] } 와 같은 형식으로 저장됩니다.</li>
  <li>폴더에 images 폴더, annotations 폴더, anchors.json 파일(추후 설명), classes.json 파일을 두고 images 폴더에 이미지를, annotations 폴더에 위의 형식의 파일을 넣어둡니다.</li>
  <li>자세한 사항은 ellipsis_to_rectangle.py 스크립트를 참고하시면 도움이 될 것 같습니다.</li>
  <li>YOLOv2에서 사용되는 k-means 기반 앵커(anchor)는 앵커 계산에 관한 스크립트(calculate_anchor_boxes.py)를 참고하시면 이해에 많은 도움이 됩니다.</li>
</ul>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://localhost:4000/assets/images/image-detection-deep-learning/example.png" target="_blank">
  <img class="full-image" src="http://localhost:4000/assets/images/image-detection-deep-learning/example.png" alt="얼굴 인식 데이터셋 예시 (annotation 변환 후)" />
</a>
<span class="caption">얼굴 인식 데이터셋 예시 (annotation 변환 후)</span></p>

<p>데이터셋은 총 2865장으로 이중 임의로 10%를 골라 약 230여장을 테스트셋으로 사용하였습니다. 클래스는 “얼굴” 한 가지로 객체가 있을 곳을 예측하고 얼굴인지 아닌지 판단하는 절차로 진행됩니다.</p>

<h3 id="datasetsdata-모듈">datasets.data 모듈</h3>

<p><code class="language-plaintext highlighter-rouge">datasets.data</code> 모듈은 데이터셋에 관련된 함수와 클래스를 가지고 있습니다. Classification 문제때와 마찬가지로, 이 모듈은 데이터셋을 메모리에 로드하고 학습 및 예측평가 과정에서 미니배치(minibatch) 단위로 제공해주는 역할을 합니다.</p>

<h4 id="read_data-및-get_best_anchor-함수">read_data 및 get_best_anchor 함수</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">pixels_per_grid</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">no_label</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="s">"""
    YOLO 디텍터를 위해 data를 로드하고, 전처리 수행
    :param data_dir: str, annotation, image 등 데이터가 저장된 경로
    :image_size: tuple, 리사이징하기 위해 지정된 이미지 사이즈
    :pixels_per_gird: int, 한 그리드당 실제 사이즈
    :no_label: bool, 레이블을 로드할 지 여부
    :return: X_set: np.ndarray, shape: (N, H, W, C).
             y_set: np.ndarray, shape: (N, g_H, g_W, anchors, 5 + num_classes).
    """</span>
    <span class="n">im_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s">'images'</span><span class="p">)</span>
    <span class="n">class_map_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s">'classes.json'</span><span class="p">)</span>
    <span class="n">anchors_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s">'anchors.json'</span><span class="p">)</span>
    <span class="n">class_map</span> <span class="o">=</span> <span class="n">load_json</span><span class="p">(</span><span class="n">class_map_path</span><span class="p">)</span>
    <span class="n">anchors</span> <span class="o">=</span> <span class="n">load_json</span><span class="p">(</span><span class="n">anchors_path</span><span class="p">)</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_map</span><span class="p">)</span>
    <span class="n">grid_h</span><span class="p">,</span> <span class="n">grid_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">image_size</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">//</span> <span class="n">pixels_per_grid</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
    <span class="n">im_paths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ext</span> <span class="ow">in</span> <span class="n">IM_EXTENSIONS</span><span class="p">:</span>
        <span class="n">im_paths</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">glob</span><span class="p">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">im_dir</span><span class="p">,</span> <span class="s">'*.{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">ext</span><span class="p">))))</span>
    <span class="n">anno_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s">'annotations'</span><span class="p">)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">im_path</span> <span class="ow">in</span> <span class="n">im_paths</span><span class="p">:</span>
        <span class="c1"># 이미지를 로드하고 지정된 사이즈로 변환
</span>        <span class="n">im</span> <span class="o">=</span> <span class="n">imread</span><span class="p">(</span><span class="n">im_path</span><span class="p">)</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">im_origina_sizes</span> <span class="o">=</span> <span class="n">im</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">im</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="p">(</span><span class="n">image_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">image_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">im</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">im</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">im</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">images</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">no_label</span><span class="p">:</span>
            <span class="n">labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">continue</span>
        <span class="c1"># 바운딩 박스를 로드하고 YOLO 모델에 맞게 변환
</span>        <span class="n">name</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">basename</span><span class="p">(</span><span class="n">im_path</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">anno_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">anno_dir</span><span class="p">,</span> <span class="s">'{}.anno'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
        <span class="n">anno</span> <span class="o">=</span> <span class="n">load_json</span><span class="p">(</span><span class="n">anno_path</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">grid_h</span><span class="p">,</span> <span class="n">grid_w</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">anchors</span><span class="p">),</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">num_classes</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">c_idx</span><span class="p">,</span> <span class="n">c_name</span> <span class="ow">in</span> <span class="n">class_map</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">c_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">anno</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">for</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="ow">in</span> <span class="n">anno</span><span class="p">[</span><span class="n">c_name</span><span class="p">]:</span>
                <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span> <span class="o">=</span> <span class="n">im_origina_sizes</span>
                <span class="c1"># 좌표를 0~1사이로 노말라이즈하고 벗어나지 않게 클립
</span>                <span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">x_min</span> <span class="o">/</span> <span class="n">ow</span><span class="p">,</span> <span class="n">y_min</span> <span class="o">/</span> <span class="n">oh</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">/</span> <span class="n">ow</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">/</span> <span class="n">oh</span>
                <span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">([</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="c1"># 값을 최적에 앵커에 지정
</span>                <span class="n">anchor_boxes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">anchors</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">ow</span><span class="p">,</span> <span class="n">oh</span><span class="p">])</span>
                <span class="n">best_anchor</span> <span class="o">=</span> <span class="n">get_best_anchor</span><span class="p">(</span>
                    <span class="n">anchor_boxes</span><span class="p">,</span> <span class="p">[</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">])</span>
                <span class="n">cx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">floor</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">x_min</span> <span class="o">+</span> <span class="n">x_max</span><span class="p">)</span> <span class="o">*</span> <span class="n">grid_w</span><span class="p">))</span>
                <span class="n">cy</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">floor</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_min</span> <span class="o">+</span> <span class="n">y_max</span><span class="p">)</span> <span class="o">*</span> <span class="n">grid_h</span><span class="p">))</span>
                <span class="n">label</span><span class="p">[</span><span class="n">cy</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">best_anchor</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">]</span>
                <span class="n">label</span><span class="p">[</span><span class="n">cy</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">best_anchor</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
                <span class="n">label</span><span class="p">[</span><span class="n">cy</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">best_anchor</span><span class="p">,</span> <span class="mi">5</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">c_idx</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

    <span class="n">X_set</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">y_set</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X_set</span><span class="p">,</span> <span class="n">y_set</span>

<span class="k">def</span> <span class="nf">get_best_anchor</span><span class="p">(</span><span class="n">anchors</span><span class="p">,</span> <span class="n">box_wh</span><span class="p">):</span>
    <span class="s">"""
    가장 높은 IOU를 가지는 anchor를 선택
    """</span>
    <span class="n">box_wh</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">box_wh</span><span class="p">)</span>
    <span class="n">best_iou</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_anchor</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">anchor</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">anchors</span><span class="p">):</span>
        <span class="n">intersect_wh</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">box_wh</span><span class="p">,</span> <span class="n">anchor</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="n">intersect_area</span> <span class="o">=</span> <span class="n">intersect_wh</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">intersect_wh</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">box_area</span> <span class="o">=</span> <span class="n">box_wh</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">box_wh</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">anchor_area</span> <span class="o">=</span> <span class="n">anchor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">anchor</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">iou</span> <span class="o">=</span> <span class="n">intersect_area</span> <span class="o">/</span> <span class="p">(</span><span class="n">box_area</span> <span class="o">+</span> <span class="n">anchor_area</span> <span class="o">-</span> <span class="n">intersect_area</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">iou</span> <span class="o">&gt;</span> <span class="n">best_iou</span><span class="p">:</span>
            <span class="n">best_iou</span> <span class="o">=</span> <span class="n">iou</span>
            <span class="n">best_anchor</span> <span class="o">=</span> <span class="n">k</span>
    <span class="k">return</span> <span class="n">best_anchor</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">load_data</code> 함수는 위의 형식으로 저장된 데이터셋을 불러와 각 이미지를 원하는 크기로 변환한뒤, ndarray 형태로 반환합니다. 마찬가지로 바운딩 박스가 저장된 annotation 파일을 불러와 get_best_anchor 함수를 이용하여 최적의 anchor에 노말라이즈(normalize)된 바운딩 박스 좌표를 지정하여 ndarray 형태로 반환합니다. 만약 이미지 사이즈가 (416, 416)이고, 앵커가 5개라면 Feature extractor인 DarkNet이 이미지 사이즈를 32배 줄여주기 때문에 그리드맵은 (13, 13)이 되며, 검출할 객체의 센터가 위치한 그리드 중 가장 IOU가 높은 앵커가 물체를 검출할 책임을 갖게 됩니다. 즉, y_set의 형태는 (N, 13, 13, 5, 좌표(4) + confidence(1) + class 개수)로 표현됩니다.</p>

<h4 id="dataset-클래스">DataSet 클래스</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DataSet</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="s">"""
        새로운 DataSet 객체를 생성함.
        :param images: np.ndarray, shape: (N, H, W, C)
        :param labels: np.ndarray, shape: (N, g_H, g_W, anchors, 5 + num_classes).
        """</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">images</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">labels</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>\
                <span class="p">(</span><span class="s">'Number of examples mismatch, between images and labels'</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_num_examples</span> <span class="o">=</span> <span class="n">images</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_images</span> <span class="o">=</span> <span class="n">images</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_labels</span> <span class="o">=</span> <span class="n">labels</span>  <span class="c1"># NOTE: this can be None, if not given.
</span>        <span class="c1"># image/label indices(can be permuted)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">_indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_num_examples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">uint</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""일부 변수를 재설정함."""</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_epochs_completed</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_index_in_epoch</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">images</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_images</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">labels</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_labels</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">num_examples</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_num_examples</span>

    <span class="k">def</span> <span class="nf">sample_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="s">"""
        'batch_size' 개수만큼 데이터들을 현재 데이터셋으로부터 추출하여 미니배치 형태로 '한번' 반환함.
        :param batch_size: int, 미니배치 크기
        :param shuffle: bool, 추출 이전에, 데이터셋 이미지를 섞을지 여부
        :return: batch_images: np.ndarray, shape: (N, H, W, C)
                 batch_labels: np.ndarray, shape: (N, g_H, g_W, anchors, 5 + num_classes)
        """</span>

        <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_num_examples</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">batch_images</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_images</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">batch_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_labels</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_labels</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">return</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_labels</span>

    <span class="k">def</span> <span class="nf">next_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="s">"""
        'batch_size' 개수만큼 데이터들을 현재 데이터셋으로부터 추출하여 미니배치 형태로 반환함.
        :param batch_size: int,  미니배치 크기
        :param shuffle: bool, 추출 이전에, 데이터셋 이미지를 섞을지 여부
        :return: batch_images: np.ndarray, shape: (N, H, W, C)
                 batch_labels: np.ndarray, shape: (N, g_H, g_W, anchors, 5 + num_classes)
        """</span>

        <span class="n">start_index</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_index_in_epoch</span>

        <span class="c1"># 맨 첫 번째 epoch에서 전체 데이터셋을 랜덤하게 섞음
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">_epochs_completed</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">start_index</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">shuffle</span><span class="p">:</span>
            <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_indices</span><span class="p">)</span>

        <span class="c1"># 현재의 인덱스가 전체 이미지 수를 넘어간 경우, 다음 epoch을 진행함
</span>        <span class="k">if</span> <span class="n">start_index</span> <span class="o">+</span> <span class="n">batch_size</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">_num_examples</span><span class="p">:</span>
            <span class="c1"># epochs 수를 1 증가
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">_epochs_completed</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="c1"># 새로운 epoch에서, 남은 데이터들을 가져옴
</span>            <span class="n">rest_num_examples</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_num_examples</span> <span class="o">-</span> <span class="n">start_index</span>
            <span class="n">indices_rest_part</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_indices</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="bp">self</span><span class="p">.</span><span class="n">_num_examples</span><span class="p">]</span>

            <span class="c1"># epoch가 끝나면, 데이터를 섞음
</span>            <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
                <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">_indices</span><span class="p">)</span>

            <span class="c1"># 다음 epoch 진행
</span>            <span class="n">start_index</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">_index_in_epoch</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">-</span> <span class="n">rest_num_examples</span>
            <span class="n">end_index</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_index_in_epoch</span>
            <span class="n">indices_new_part</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_indices</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="n">end_index</span><span class="p">]</span>

            <span class="n">images_rest_part</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_images</span><span class="p">[</span><span class="n">indices_rest_part</span><span class="p">]</span>
            <span class="n">images_new_part</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_images</span><span class="p">[</span><span class="n">indices_new_part</span><span class="p">]</span>
            <span class="n">batch_images</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">(</span><span class="n">images_rest_part</span><span class="p">,</span> <span class="n">images_new_part</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">labels_rest_part</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_labels</span><span class="p">[</span><span class="n">indices_rest_part</span><span class="p">]</span>
                <span class="n">labels_new_part</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_labels</span><span class="p">[</span><span class="n">indices_new_part</span><span class="p">]</span>
                <span class="n">batch_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">labels_rest_part</span><span class="p">,</span> <span class="n">labels_new_part</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_labels</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">_index_in_epoch</span> <span class="o">+=</span> <span class="n">batch_size</span>
            <span class="n">end_index</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_index_in_epoch</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_indices</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="n">end_index</span><span class="p">]</span>
            <span class="n">batch_images</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_images</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">batch_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_labels</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_labels</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="k">return</span> <span class="n">batch_images</span><span class="p">,</span> <span class="n">batch_labels</span>
</code></pre></div></div>
<p>Classification 문제때와 마찬가지로 DataSet 클래스를 이용하여 메모리에 로드된 X_set과 y_set을 미니배치(minibatch) 단위로 반환해 줍니다.</p>

<h3 id="2-성능-평가-재현율recall">(2) 성능 평가: 재현율(Recall)</h3>

<p>모델의 얼굴인식 성능 평가를 위해 <strong>재현율(Recall)</strong>을 사용합니다. Detection에서는 mAP(mean average precision)가 가장 빈번하게 사용되는 성능 척도이나, 클래스가 한가지밖에 없어 평균의 의미가 없고 물체로 인식한 대상이 높은 확률로 분류까지 하는 지 확인할 수 있는 재현율이 더 직관적이라 판단하여 재현율을 성능 평가 척도로 사용하였습니다. 요약하면, 테스트를 위해 주어진 전체 오브젝트 수 대비, 실제 ground truth 바운딩 박스와 예측한 바운딩 박스의 IOU(Intersection of Union)가 특정 임계값 이상일 때 올바르게 분류한 오브젝트 수로 재현율을 정의합니다.</p>

<p>\begin{equation}
\text{Recall} = \frac{\text{위치를 찾고 올바르게 분류한 오브젝트 수}} {\text{전체 오브젝트 수}}
\end{equation}</p>

<h3 id="learningevaluators-모듈">learning.evaluators 모듈</h3>

<p>Classification 문제와 마찬가지로, 성능 평가를 위한 ‘evaluator’ 클래스를 담고 있습니다.</p>

<h4 id="evaluator-클래스">Evaluator 클래스</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Evaluator</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="s">"""성능 평가를 위한 evaluator의 베이스 클래스."""</span>

    <span class="o">@</span><span class="n">abstractproperty</span>
    <span class="k">def</span> <span class="nf">worst_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""
        최저 성능 점수.
        :return float.
        """</span>
        <span class="k">pass</span>

    <span class="o">@</span><span class="n">abstractproperty</span>
    <span class="k">def</span> <span class="nf">mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""
        점수가 높아야 성능이 우수한지, 낮아야 성능이 우수한지 여부. 'max'와 'min' 중 하나.
        e.g. 정확도, AUC, 정밀도, 재현율 등의 경우 'max',
             오류율, 미검률, 오검률 등의 경우 'min'.
        :return: str.
        """</span>
        <span class="k">pass</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
        <span class="s">"""
        실제로 사용할 성능 평가 지표.
        해당 함수를 추후 구현해야 함.
        :param y_true: np.ndarray, shape: (N, num_classes).
        :param y_pred: np.ndarray, shape: (N, num_classes).
        :return float.
        """</span>
        <span class="k">pass</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">is_better</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">curr</span><span class="p">,</span> <span class="n">best</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        현재 주어진 성능 점수가 현재까지의 최고 성능 점수보다 우수한지 여부를 반환하는 함수.
        해당 함수를 추후 구현해야 함.
        :param curr: float, 평가 대상이 되는 현재 성능 점수.
        :param best: float, 현재까지의 최고 성능 점수.
        :return bool.
        """</span>
        <span class="k">pass</span>
</code></pre></div></div>

<p>추상 베이스 클래스입니다. 다른 부분은 모두 Classification 문제에서 서술한 내용과 같아 추가 설명은 생략하겠습니다.</p>

<h4 id="recallevaluator-클래스">RecallEvaluator 클래스</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RecallEvaluator</span><span class="p">(</span><span class="n">Evaluator</span><span class="p">):</span>
    <span class="s">""" 재현율(Recall)을 성능 평가 청도로 사용하는 evaluator 클래스"""</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">worst_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""최저 성능 점수"""</span>
        <span class="k">return</span> <span class="mf">0.0</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""점수가 높아야 성능이 우수한지 낮아야 우수한지 여부"""</span>
        <span class="k">return</span> <span class="s">'max'</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        주어진 바운딩 박스에 대한 Recall 성능 평가 점수
        :param kwargs: dict, 추가 인자.
            - nms_flag: bool, True면 nms 수행
        """</span>
        <span class="n">nms_flag</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'nms_flag'</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nms_flag</span><span class="p">:</span>
            <span class="n">bboxes</span> <span class="o">=</span> <span class="n">predict_nms_boxes</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bboxes</span> <span class="o">=</span> <span class="n">convert_boxes</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">gt_bboxes</span> <span class="o">=</span> <span class="n">convert_boxes</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">cal_recall</span><span class="p">(</span><span class="n">gt_bboxes</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span>

    <span class="k">def</span> <span class="nf">is_better</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">curr</span><span class="p">,</span> <span class="n">best</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        상대적 문턱값을 고려하여, 현재 주어진 성능 점수가 현재까지의 최고 성능 점수보다
        우수한지 여부를 반환하는 함수.
        :param kwargs: dict, 추가 인자.
            - score_threshold: float, 새로운 최적값 결정을 위한 상대적 문턱값으로,
                               유의미한 차이가 발생했을 경우만을 반영하기 위함.
        """</span>
        <span class="n">score_threshold</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'score_threshold'</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
        <span class="n">relative_eps</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="n">score_threshold</span>
        <span class="k">return</span> <span class="n">curr</span> <span class="o">&gt;</span> <span class="n">best</span> <span class="o">*</span> <span class="n">relative_eps</span>
</code></pre></div></div>

<p>재현율을 성능 평가 척도로 사용하기 위해 상속받아 RecallEvaluator 클래스를 구현하였습니다. <code class="language-plaintext highlighter-rouge">score</code> 함수에서 재현율을 계산하기 위해, learning.utils 모듈에 cal_recall 함수를 구현해두었습니다. 재현율은 높을 수록 좋기에 <code class="language-plaintext highlighter-rouge">mode</code> 함수는 max로 <code class="language-plaintext highlighter-rouge">is_better</code> 함수는 특정 임계값을 넘었을 때 최고 성능이 바뀌도록 구현하였습니다.</p>

<h2 id="러닝-모델-yolov2">러닝 모델: YOLOv2</h2>

<p>러닝 모델로는 앞서 말씀드린 YOLOv2를 사용합니다. 이전과 마찬가지로 주로 사용하는 층(layers)들을 생성하는 함수를 models.layers 모듈에서 정의하고, models.nn 모듈에서 일반적인 Detection용 컨볼루션 신경망 모델을 정의하고 YOLOv2 클래스가 상속받는 형식으로 구현하였습니다.</p>

<h3 id="modelslayers-모듈">models.layers 모듈</h3>

<p><code class="language-plaintext highlighter-rouge">models.layers</code> 모듈은 classification 문제때와 거의 같으며, 추가로 batchNormalization layer를 함수로 정의하였습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">weight_variable</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="s">"""
    새로운 가중치 변수를 주어진 shape에 맞게 선언하고,
    Normal(0.0, stddev^2)의 정규분포로부터의 샘플링을 통해 초기화함.
    :param shape: list(int).
    :param stddev: float, 샘플링 대상이 되는 정규분포의 표준편차 값.
    :return weights: tf.Variable.
    """</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'weights'</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span>
                              <span class="n">tf</span><span class="p">.</span><span class="n">random_normal_initializer</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">stddev</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">weights</span>


<span class="k">def</span> <span class="nf">bias_variable</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="s">"""
    새로운 바이어스 변수를 주어진 shape에 맞게 선언하고, 
    주어진 상수값으로 추기화함.
    :param shape: list(int).
    :param value: float, 바이어스의 초기화 값.
    :return biases: tf.Variable.
    """</span>
    <span class="n">biases</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'biases'</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span>
                             <span class="n">tf</span><span class="p">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">biases</span>


<span class="k">def</span> <span class="nf">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">):</span>
    <span class="s">"""
    주어진 입력값과 필터 가중치 간의 2D 컨볼루션을 수행함.
    :param x: tf.Tensor, shape: (N, H, W, C).
    :param W: tf.Tensor, shape: (fh, fw, ic, oc).
    :param stride: int, 필터의 각 방향으로의 이동 간격.
    :param padding: str, 'SAME' 또는 'VALID',
                         컨볼루션 연산 시 입력값에 대해 적용할 패딩 알고리즘.
    :return: tf.Tensor.
    """</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">max_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">side_l</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">):</span>
    <span class="s">"""
    주어진 입력값에 대해 최댓값 풀링(max pooling)을 수행함.
    :param x: tf.Tensor, shape: (N, H, W, C).
    :param side_l: int, 풀링 윈도우의 한 변의 길이.
    :param stride: int, 풀링 윈도우의 각 방향으로의 이동 간격. 
    :param padding: str, 'SAME' 또는 'VALID',
                         풀링 연산 시 입력값에 대해 적용할 패딩 알고리즘.
    :return: tf.Tensor.
    """</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">side_l</span><span class="p">,</span> <span class="n">side_l</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                          <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">conv_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">side_l</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">out_depth</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="s">"""
    새로운 컨볼루션 층을 추가함.
    :param x: tf.Tensor, shape: (N, H, W, C).
    :param side_l: int, 필터 한 변의 길이
    :param stride: int, 필터의 각 방향으로의 이동 간격
    :param out_depth: int, 입력값에 적용할 필터의 총 개수
    :param padding: str, 'SAME' 또는 'VALID',
                         컨볼루션 연산 시 입력값에 대해 적용할 패딩 알고리즘
    :param use_bias: bool, True이면, 바이어스 값을 사용, 아니면 사용하지 않음.
                          전형적으로 batchnormalization 층이 이후에 나오면 바이어스를 사용하지 않음.
    :param kwargs: dict, 추가 인자, 가중치/바이어스 초기화를 위한 하이퍼파라미터들을 포함함.
        - weight_stddev: float, 샘플링 대상이 되는 정규분포의 표준편차 값.
        - biases_value: float, 바이어스의 초기화 값.
    :return: tf.Tensor.
    """</span>
    <span class="n">weights_stddev</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'weights_stddev'</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">in_depth</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">filters</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">([</span><span class="n">side_l</span><span class="p">,</span> <span class="n">side_l</span><span class="p">,</span> <span class="n">in_depth</span><span class="p">,</span> <span class="n">out_depth</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="n">weights_stddev</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">use_bias</span><span class="p">:</span>
        <span class="n">biases_value</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'biases_value'</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="n">biases</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">([</span><span class="n">out_depth</span><span class="p">],</span> <span class="n">value</span><span class="o">=</span><span class="n">biases_value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">batchNormalization</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">is_train</span><span class="p">):</span>
    <span class="s">"""
    새로운 batchNormalization 층을 추가함.
    :param x: tf.Tensor, shape: (N, H, W, C) or (N, D)
    :param is_train: tf.placeholder(bool), True이면 train mode, 아니면 test mode
    :return: tf.Tensor.
    """</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">batch_normalization</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">is_train</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fc_layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="s">"""
    새로운 완전 연결 층을 추가함.
    :param x: tf.Tensor, shape: (N, D).
    :param out_dim: int, 출력 벡터의 차원수.
    :param kwargs: dict, 추가 인자, 가중치/바이어스 초기화를 위한 하이퍼파라미터들을 포함함. 
        - weight_stddev: float, 샘플링 대상이 되는 정규분포의 표준편차 값.
        - biases_value: float, 바이어스의 초기화 값.
    :return: tf.Tensor.
    """</span>
    <span class="n">weights_stddev</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'weights_stddev'</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">biases_value</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'biases_value'</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">in_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="n">weight_variable</span><span class="p">([</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="n">weights_stddev</span><span class="p">)</span>
    <span class="n">biases</span> <span class="o">=</span> <span class="n">bias_variable</span><span class="p">([</span><span class="n">out_dim</span><span class="p">],</span> <span class="n">value</span><span class="o">=</span><span class="n">biases_value</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span>
</code></pre></div></div>
<p>BatchNormalization 층은 보통 컨볼루션 층 이후에 나오며, 이 때 컨볼루션에서 보통 추가로 더해지는 바이어스는 필요하지 않습니다. 이에 conv_layer 함수를 일부 수정하였습니다.</p>

<h3 id="modelsnn-모듈">models.nn 모듈</h3>

<p><code class="language-plaintext highlighter-rouge">models.nn</code> 모듈은 마찬가지로 신경망을 표현하는 클래스를 가지고 있습니다.</p>

<h4 id="detectnet-클래스">DetectNet 클래스</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DetectNet</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="s">"""Detection을 위한 컨볼루션 신경망 모델의 베이스 클래스."""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        모델 생성자.
        :param input_shape: tuple, shape (H, W, C)
        :param num_classes: int, 총 클래스 개수
        """</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">input_shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">is_train</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nb">bool</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_build_model</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">d</span><span class="p">[</span><span class="s">'pred'</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_build_loss</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_build_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        모델 생성.
        해당 함수를 추후 구현해야 함.
        """</span>
        <span class="k">pass</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_build_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        모델 학습을 위한 손실 함수 생성.
        해당 함수를 추후 구현해야 함.
        """</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        주어진 데이터셋에 대한 예측을 수행함.
        :param sess: tf.Session.
        :param dataset: DataSet.
        :param verbose: bool, 예측 과정에서 구체적인 정보를 출력할지 여부.
        :param kwargs: dict, 예측을 위한 추가 인자.
                -batch_size: int, 각 반복 회차에서의 미니배치 크기.
        :return _y_pred: np.ndarray, shape (N, 5 + number of classes) 
        """</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'batch_size'</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>

        <span class="n">num_classes</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_classes</span>
        <span class="n">pred_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">num_examples</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="n">pred_size</span> <span class="o">//</span> <span class="n">batch_size</span>
        <span class="n">flag</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">bool</span><span class="p">(</span><span class="n">pred_size</span> <span class="o">%</span> <span class="n">batch_size</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'Running prediction loop...'</span><span class="p">)</span>

        <span class="c1"># Start prediction loop
</span>        <span class="n">_y_pred</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="o">+</span><span class="n">flag</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">num_steps</span> <span class="ow">and</span> <span class="n">flag</span><span class="p">:</span>
                <span class="n">_batch_size</span> <span class="o">=</span> <span class="n">pred_size</span> <span class="o">-</span> <span class="n">num_steps</span><span class="o">*</span><span class="n">batch_size</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">_batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

            <span class="c1"># Compute predictions
</span>            <span class="c1"># (N, grid_h, grid_w, 5 + num_classes)
</span>            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pred_y</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                              <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_train</span><span class="p">:</span> <span class="bp">False</span><span class="p">})</span>

            <span class="n">_y_pred</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'Total prediction time(sec): {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>

        <span class="n">_y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">_y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_y_pred</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">DetectNet</code> 클래스는 , 기본 추상 베이스 클래스로, 확장성을 위해 전반적인 Detection Network를 포괄하도록 구현하였습니다. <code class="language-plaintext highlighter-rouge">_build_model</code> 과 <code class="language-plaintext highlighter-rouge">_build_loss</code> 함수는 <code class="language-plaintext highlighter-rouge">DetectNet</code>의 자식 클래스에서 구현하도록 하였고, <code class="language-plaintext highlighter-rouge">predict</code> 함수는 모델의 예측 결과를 반환합니다. 보통 Detection의 예측 결과는 nms(Non Maximum Suppression)을 거치지 않았을 때 총 바운딩 박스마다 좌표와 클래스 확률을 나타내는데, <strong>YOLO</strong>의 경우 background class의 확률이 없는 대신, 바운딩 박스의 신뢰도(confidence) 점수를 가지고 있습니다. 하지만 전반적인 모양은 거의 같기 때문에 베이스 클래스에서 구현하였습니다.</p>

<h4 id="yolo-클래스">YOLO 클래스</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">YOLO</span><span class="p">(</span><span class="n">DetectNet</span><span class="p">):</span>
    <span class="s">"""YOLO class"""</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">anchors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># YOLO 신경망을 위한 추가 생성자
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">grid_size</span> <span class="o">=</span> <span class="n">grid_size</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">//</span> <span class="mi">32</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_anchors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">anchors</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">anchors</span> <span class="o">=</span> <span class="n">anchors</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span> <span class="o">+</span>
                                <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">grid_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">grid_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_anchors</span><span class="p">,</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">num_classes</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">YOLO</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_build_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        모델 생성
        :param kwargs: dict, YOLO 생성을 위한 추가 인자.
                -image_mean: np.ndarray, 평균 이미지: 이미지들의 각 일벽 채널별 평균값, shape: (C,).
        :return d: dict, 각 층에서의 출력값들을 포함함
        """</span>
        <span class="n">d</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">x_mean</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'image_mean'</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

        <span class="c1"># input
</span>        <span class="n">X_input</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">X</span> <span class="o">-</span> <span class="n">x_mean</span>
        <span class="n">is_train</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_train</span>

        <span class="c1">#conv1 - batch_norm1 - leaky_relu1 - pool1
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer1'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">X_input</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv1'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm1'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'pool1'</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu1'</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">)</span>
        <span class="c1"># (416, 416, 3) --&gt; (208, 208, 32)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer1.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'pool1'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv2 - batch_norm2 - leaky_relu2 - pool2
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer2'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'pool1'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv2'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm2'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'pool2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu2'</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">)</span>
        <span class="c1"># (208, 208, 32) --&gt; (104, 104, 64)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer2.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'pool2'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv3 - batch_norm3 - leaky_relu3
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer3'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv3'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'pool2'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm3'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv3'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu3'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm3'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (104, 104, 64) --&gt; (104, 104, 128)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer3.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu3'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv4 - batch_norm4 - leaky_relu4
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer4'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv4'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu3'</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm4'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv4'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu4'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm4'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (104, 104, 128) --&gt; (104, 104, 64)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer4.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu4'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv5 - batch_norm5 - leaky_relu5 - pool5
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer5'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu4'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv5'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm5'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'pool5'</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu5'</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">)</span>
        <span class="c1"># (104, 104, 64) --&gt; (52, 52, 128)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer5.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'pool5'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv6 - batch_norm6 - leaky_relu6
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer6'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv6'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'pool5'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm6'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv6'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu6'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm6'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (52, 52, 128) --&gt; (52, 52, 256)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer6.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu6'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv7 - batch_norm7 - leaky_relu7
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer7'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv7'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu6'</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">biases_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm7'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv7'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu7'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm7'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (52, 52, 256) --&gt; (52, 52, 128)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer7.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu7'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv8 - batch_norm8 - leaky_relu8 - pool8
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer8'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv8'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu7'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm8'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv8'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu8'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm8'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'pool8'</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu8'</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">)</span>
        <span class="c1"># (52, 52, 128) --&gt; (26, 26, 256)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer8.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'pool8'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv9 - batch_norm9 - leaky_relu9
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer9'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv9'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'pool8'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span>
                                    <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm9'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv9'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu9'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm9'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (26, 26, 256) --&gt; (26, 26, 512)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer9.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu9'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv10 - batch_norm10 - leaky_relu10
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer10'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv10'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu9'</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm10'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv10'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu10'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm10'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (26, 26, 512) --&gt; (26, 26, 256)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer10.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu10'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv11 - batch_norm11 - leaky_relu11
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer11'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv11'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu10'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm11'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv11'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu11'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm11'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (26, 26, 256) --&gt; (26, 26, 512)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer11.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu11'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv12 - batch_norm12 - leaky_relu12
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer12'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv12'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu11'</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm12'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv12'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu12'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm12'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (26, 26, 512) --&gt; (26, 26, 256)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer12.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu12'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv13 - batch_norm13 - leaky_relu13 - pool13
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer13'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv13'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu12'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm13'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv13'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu13'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm13'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'pool13'</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu13'</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">)</span>
        <span class="c1"># (26, 26, 256) --&gt; (13, 13, 512)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer13.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'pool13'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv14 - batch_norm14 - leaky_relu14
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer14'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv14'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'pool13'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm14'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv14'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu14'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm14'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (13, 13, 512) --&gt; (13, 13, 1024)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer14.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu14'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv15 - batch_norm15 - leaky_relu15
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer15'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv15'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu14'</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm15'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv15'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu15'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm15'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (13, 13, 1024) --&gt; (13, 13, 512)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer15.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu15'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv16 - batch_norm16 - leaky_relu16
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer16'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv16'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu15'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm16'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv16'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu16'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm16'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (13, 13, 512) --&gt; (13, 13, 1024)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer16.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu16'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv17 - batch_norm16 - leaky_relu17
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer17'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv17'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu16'</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm17'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv17'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu17'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm17'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (13, 13, 1024) --&gt; (13, 13, 512)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer17.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu17'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv18 - batch_norm18 - leaky_relu18
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer18'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv18'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu17'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm18'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv18'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu18'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm18'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (13, 13, 512) --&gt; (13, 13, 1024)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer18.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu18'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv19 - batch_norm19 - leaky_relu19
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer19'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv19'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu18'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm19'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv19'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu19'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm19'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (13, 13, 1024) --&gt; (13, 13, 1024)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer19.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu19'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv20 - batch_norm20 - leaky_relu20
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer20'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv20'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu19'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm20'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv20'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu20'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm20'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (13, 13, 1024) --&gt; (13, 13, 1024)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer20.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu20'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1"># concatenate layer20 and layer 13 using space to depth
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer21'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'skip_connection'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu13'</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span>
                                              <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">eights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'skip_batch'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span>
                <span class="n">d</span><span class="p">[</span><span class="s">'skip_connection'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'skip_leaky_relu'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'skip_batch'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'skip_space_to_depth_x2'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">space_to_depth</span><span class="p">(</span>
                <span class="n">d</span><span class="p">[</span><span class="s">'skip_leaky_relu'</span><span class="p">],</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'concat21'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="s">'skip_space_to_depth_x2'</span><span class="p">],</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu20'</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># (13, 13, 1024) --&gt; (13, 13, 256+1024)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer21.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'concat21'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="c1">#conv22 - batch_norm22 - leaky_relu22
</span>        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'layer22'</span><span class="p">):</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'conv22'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'concat21'</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span>
                                     <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'batch_norm22'</span><span class="p">]</span> <span class="o">=</span> <span class="n">batchNormalization</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'conv22'</span><span class="p">],</span> <span class="n">is_train</span><span class="p">)</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu22'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'batch_norm22'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="c1"># (13, 13, 1280) --&gt; (13, 13, 1024)
</span>        <span class="k">print</span><span class="p">(</span><span class="s">'layer22.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu22'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>

        <span class="n">output_channel</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_anchors</span> <span class="o">*</span> <span class="p">(</span><span class="mi">5</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_classes</span><span class="p">)</span>
        <span class="n">d</span><span class="p">[</span><span class="s">'logit'</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s">'leaky_relu22'</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">output_channel</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="s">'SAME'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">weights_stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">biases_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="n">d</span><span class="p">[</span><span class="s">'pred'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">d</span><span class="p">[</span><span class="s">'logit'</span><span class="p">],</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">grid_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">grid_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_anchors</span><span class="p">,</span> <span class="mi">5</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_classes</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'pred.shape'</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s">'pred'</span><span class="p">].</span><span class="n">get_shape</span><span class="p">().</span><span class="n">as_list</span><span class="p">())</span>
        <span class="c1"># (13, 13, 1024) --&gt; (13, 13, num_anchors , (5 + num_classes))
</span>
        <span class="k">return</span> <span class="n">d</span>

    <span class="k">def</span> <span class="nf">_build_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        모델 학습을 위한 손실 함수 생성
        :param kwargs: dict, 추가 인자
                - loss_weights: list, 각 좌표, 신뢰도, 클래스 분류 확률에 대한 가중치 리스트
        :return tf.Tensor.
        """</span>

        <span class="n">loss_weights</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'loss_weights'</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
        <span class="c1"># DEBUG
</span>        <span class="c1"># loss_weights = kwargs.pop('loss_weights', [1.0, 1.0, 1.0, 1.0, 1.0])
</span>        <span class="n">grid_h</span><span class="p">,</span> <span class="n">grid_w</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">grid_size</span>
        <span class="n">num_classes</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_classes</span>
        <span class="n">anchors</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">anchors</span>
        <span class="n">grid_wh</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">grid_w</span><span class="p">,</span> <span class="n">grid_h</span><span class="p">],</span> <span class="p">[</span>
                             <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">cxcy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">transpose</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">grid_w</span><span class="p">),</span> <span class="n">grid_h</span><span class="p">),</span>
                             <span class="n">np</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">grid_h</span><span class="p">),</span> <span class="n">grid_w</span><span class="p">)])</span>
        <span class="n">cxcy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">cxcy</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">grid_h</span><span class="p">,</span> <span class="n">grid_w</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="n">txty</span><span class="p">,</span> <span class="n">twth</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pred</span><span class="p">[...,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">pred</span><span class="p">[...,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
        <span class="n">confidence</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pred</span><span class="p">[...,</span> <span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
        <span class="n">class_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">pred</span><span class="p">[...,</span> <span class="mi">5</span><span class="p">:],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">num_classes</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">tf</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pred</span><span class="p">[...,</span> <span class="mi">5</span><span class="p">:])</span>
        <span class="n">bxby</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">txty</span><span class="p">)</span> <span class="o">+</span> <span class="n">cxcy</span>
        <span class="n">pwph</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">anchors</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_anchors</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="mi">32</span>
        <span class="n">bwbh</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">twth</span><span class="p">)</span> <span class="o">*</span> <span class="n">pwph</span>

        <span class="c1"># 예측(Prediction)을 위한 클래스 변수
</span>        <span class="n">nxny</span><span class="p">,</span> <span class="n">nwnh</span> <span class="o">=</span> <span class="n">bxby</span> <span class="o">/</span> <span class="n">grid_wh</span><span class="p">,</span> <span class="n">bwbh</span> <span class="o">/</span> <span class="n">grid_wh</span>
        <span class="n">nx1ny1</span><span class="p">,</span> <span class="n">nx2ny2</span> <span class="o">=</span> <span class="n">nxny</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">nwnh</span><span class="p">,</span> <span class="n">nxny</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">nwnh</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pred_y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span>
            <span class="p">(</span><span class="n">nx1ny1</span><span class="p">,</span> <span class="n">nx2ny2</span><span class="p">,</span> <span class="n">confidence</span><span class="p">,</span> <span class="n">class_probs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 각 앵커마다 IOU 계산
</span>        <span class="n">num_objects</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
        <span class="n">max_nx1ny1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">nx1ny1</span><span class="p">)</span>
        <span class="n">min_nx2ny2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">minimum</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span> <span class="n">nx2ny2</span><span class="p">)</span>
        <span class="n">intersect_wh</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">min_nx2ny2</span> <span class="o">-</span> <span class="n">max_nx1ny1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="n">intersect_area</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_prod</span><span class="p">(</span><span class="n">intersect_wh</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">intersect_area</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">tf</span><span class="p">.</span><span class="n">equal</span><span class="p">(</span><span class="n">intersect_area</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">intersect_area</span><span class="p">),</span> <span class="n">intersect_area</span><span class="p">)</span>
        <span class="n">gt_box_area</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_prod</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">box_area</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_prod</span><span class="p">(</span><span class="n">nx2ny2</span> <span class="o">-</span> <span class="n">nx1ny1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">iou</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">truediv</span><span class="p">(</span>
            <span class="n">intersect_area</span><span class="p">,</span> <span class="p">(</span><span class="n">gt_box_area</span> <span class="o">+</span> <span class="n">box_area</span> <span class="o">-</span> <span class="n">intersect_area</span><span class="p">))</span>
        <span class="n">sum_iou</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">iou</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">iou</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">truediv</span><span class="p">(</span><span class="n">sum_iou</span><span class="p">,</span> <span class="n">num_objects</span><span class="p">)</span>


        <span class="c1"># 손실 함수를 위한 변수 생성 및 계산
</span>        <span class="n">gt_bxby</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span> <span class="o">*</span> <span class="n">grid_wh</span>
        <span class="n">gt_bwbh</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">grid_wh</span>

        <span class="n">resp_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
        <span class="n">no_resp_mask</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">resp_mask</span>
        <span class="n">gt_confidence</span> <span class="o">=</span> <span class="n">resp_mask</span> <span class="o">*</span> <span class="n">tf</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">iou</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">gt_class_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">y</span><span class="p">[...,</span> <span class="mi">5</span><span class="p">:]</span>

        <span class="n">loss_bxby</span> <span class="o">=</span> <span class="n">loss_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">resp_mask</span> <span class="o">*</span> \
            <span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">gt_bxby</span> <span class="o">-</span> <span class="n">bxby</span><span class="p">)</span>
        <span class="n">loss_bwbh</span> <span class="o">=</span> <span class="n">loss_weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">resp_mask</span> <span class="o">*</span> \
            <span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">gt_bwbh</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">bwbh</span><span class="p">))</span>
        <span class="n">loss_resp_conf</span> <span class="o">=</span> <span class="n">loss_weights</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">resp_mask</span> <span class="o">*</span> \
            <span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">gt_confidence</span> <span class="o">-</span> <span class="n">confidence</span><span class="p">)</span>
        <span class="n">loss_no_resp_conf</span> <span class="o">=</span> <span class="n">loss_weights</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="n">no_resp_mask</span> <span class="o">*</span> \
            <span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">gt_confidence</span> <span class="o">-</span> <span class="n">confidence</span><span class="p">)</span>
        <span class="n">loss_class_probs</span> <span class="o">=</span> <span class="n">loss_weights</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">resp_mask</span> <span class="o">*</span> \
            <span class="n">tf</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">gt_class_probs</span> <span class="o">-</span> <span class="n">class_probs</span><span class="p">)</span>

       <span class="c1"># 각 손실 함수 (xy, wh, confidence, no_confidence, class_probs)를 합친 뒤 평균내어 총 손실 함수 반환
</span>        <span class="n">merged_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">concat</span><span class="p">((</span>
                                <span class="n">loss_bxby</span><span class="p">,</span>
                                <span class="n">loss_bwbh</span><span class="p">,</span>
                                <span class="n">loss_resp_conf</span><span class="p">,</span>
                                <span class="n">loss_no_resp_conf</span><span class="p">,</span>
                                <span class="n">loss_class_probs</span>
                                <span class="p">),</span>
                                <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">merged_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">total_loss</span>

</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">YOLO</code> 클래스는 우선 YOLO에서 추가로 사용되는 변수를 생성합니다. Classification과 다르게 Detection에서 학습에서 사용되는 라벨(y)은 각 신경망마다 다른 경우가 많기 때문에 자식 클래스에서 구현하였습니다. 또 그리드의 크기와 앵커 개수 등을 추가로 생성하여 이후 손실 함수에 사용되게 하였습니다.</p>

<p>아키텍쳐 부분에서는 원 논문의 Darknet(layer1 ~ layer19) 및 YOLO Detector(layer20 ~ layer22)부분을 최대한 같게 구현하였습니다. 원 논문에서는 Darknet을 ImageNet Challenge 데이터셋으로 학습시켜 Feature extractor 성능을 끌어올렸으나, 이번 포스팅에선 그 부분을 생략하였습니다.</p>

<p>손실 함수의 경우 Classification 때보다 다소 복잡합니다. dataset.data 모듈에서 설명한 것과 같이 책임을 갖는 앵커의 경우 검출할 객체의 좌표, 그 박스의 신뢰도(confidence), 클래스의 확률(class_probs)의 차이의 제곱을 총 손실로 가지며, 책임이 없는 앵커는 신뢰도가 0이 되게끔 손실을 줘 학습을 진행합니다. 제 부족한 설명으로 이해가 잘 안될 것 같은데요, 앞서 정의한 <code class="language-plaintext highlighter-rouge">_build_loss</code> 함수 부분과 밑의 손실 함수 수식을 차근차근 따라가면 이해에 큰 도움이 될 것 같습니다!</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://localhost:4000/assets/images/image-detection-deep-learning/yolo_loss_function.jpg" target="_blank">
  <img class="large-image" src="http://localhost:4000/assets/images/image-detection-deep-learning/yolo_loss_function.jpg" alt="YOLO 신경망의 손실 함수 수식" />
</a>
<span class="caption">YOLO 신경망의 손실 함수 수식</span></p>

<h2 id="4-러닝-알고리즘-sgdmomentum">(4) 러닝 알고리즘: SGD+Momentum</h2>

<p>러닝 알고리즘은 Classification 문제때와 크게 다르지 않습니다. 마찬가지로 <strong>모멘텀(momentum)</strong>을 적용한 <strong>확률적 경사 하강법(stochastic gradient descent; 이하 SGD)</strong>을 채택하였으며, 베이스 클래스를 먼저 정의한 뒤, 이를 모멘텀 SGD에 기반한 optimizer 클래스가 상속받는 형태로 구현하였습니다.(추가로 Adam Opimizer 클래스도 구현해두었으니 관심이 있으신 분은 저장소에서 확인 후 이를 이용하여 학습도 해보시길 추천드립니다.)</p>

<h3 id="learningoptimizers-모듈">learning.optimizers 모듈</h3>

<h4 id="optimizer-클래스">Optimizer 클래스</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Optimizer</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="s">"""경사 하강 러닝 알고리즘 기반 optimizer의 베이스 클래스"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">evaluator</span><span class="p">,</span> <span class="n">val_set</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        Optimizer 생성자.
        :param model: Net, 학습할 모델.
        :param train_set: DataSet, 학습에 사용할 학습 데이터셋.
        :param evaluator: Evaluator, 학습 수행 과정에서 성능 평가에 사용할 evaluator.
        :param val_set: Datset, 검증 데이터셋, 주어지지 않은 경우 None으로 남겨둘 수 있음.
        :param kwargs: dict, 학습 관련 하이퍼파라미터로 구성된 추가 인자.
                - batch_size: int, 각 반복 회차에서의 미니배치 크기.
                - num_epochs: int, 총 epoch 수.
                - init_learning_rate: float, 학습률 초기값.
        """</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">train_set</span> <span class="o">=</span> <span class="n">train_set</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">evaluator</span> <span class="o">=</span> <span class="n">evaluator</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">val_set</span> <span class="o">=</span> <span class="n">val_set</span>

        <span class="c1"># 학습 관련 하이퍼파라미터
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'batch_size'</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'num_epochs'</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">init_learning_rate</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'init_learning_rate'</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate_placeholder</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">optimize</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_optimize_op</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"""일부 변수를 재설정."""</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">curr_epoch</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="c1"># number of bad epochs, where the model is updated without improvement.
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">num_bad_epochs</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># initialize best score with the worst one
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">evaluator</span><span class="p">.</span><span class="n">worst_score</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">curr_learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">init_learning_rate</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_optimize_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        경사 하강 업데이트를 위한 tf.train.Optimizer.minimize Op.
        해당 함수를 추후 구현해야 하며, 외부에서 임의로 호출할 수 없음.
        """</span>
        <span class="k">pass</span>

    <span class="o">@</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">_update_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        고유의 학습률 스케줄링 방법에 따라, (필요한 경우) 매 epoch마다 현 학습률 값을 업데이트함.
        해당 함수를 추후 구현해야 하며, 외부에서 임의로 호출할 수 없음.
        """</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        경사 하강 업데이트를 1회 수행하며, 관련된 값을 반환함.
        해당 함수를 추후 구현해야 하며, 외부에서 임의로 호출할 수 없음.
        :param sess, tf.Session.
        :return loss: float, 1회 반복 회차 결과 손실 함수값.
                y_true: np.ndarray, 학습 데이터셋의 실제 레이블.
                y_pred: np.ndarray, 모델이 반환한 예측 레이블.
        """</span>

        <span class="c1"># 미니배치 하나를 추출함
</span>        <span class="n">X</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">train_set</span><span class="p">.</span><span class="n">next_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="c1"># 손실 함수값을 계산하고, 모델 업데이트를 수행.
</span>        <span class="n">_</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> \
            <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">([</span><span class="bp">self</span><span class="p">.</span><span class="n">optimize</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">pred_y</span><span class="p">],</span>
                     <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">X</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">y</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">is_train</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate_placeholder</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">curr_learning_rate</span><span class="p">})</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">X</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">save_dir</span><span class="o">=</span><span class="s">'/tmp'</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        Optimizer를 실행하고, 모델을 학습함.
        :param sess: tf.Session.
        :param save_dir: str, 학습된 모델의 파라미터들을 저장할 디렉터리 경로.
        :param details: bool, 학습 결과 관련 구체적인 정보를, 학습 종료 후 반환할지 여부.
        :param verbose: bool, 학습 과정에서 구체적인 정보를 출력할지 여부.
        :param kwargs: dict, 학습 관련 하이퍼파라미터로 구성된 추가 인자.
                - nms_flag: bool, nms(non maximum supression)를 수행할 지 여부.
        :return train_results: dict, 구체적인 학습 결과를 담은 dict
        """</span>
        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">Saver</span><span class="p">()</span>
        <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>  <span class="c1"># 전체 파라미터들을 초기화함
</span>
        <span class="n">train_results</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">train_size</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">train_set</span><span class="p">.</span><span class="n">num_examples</span>
        <span class="n">num_steps_per_epoch</span> <span class="o">=</span> <span class="n">train_size</span> <span class="o">//</span> <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_epochs</span> <span class="o">*</span> <span class="n">num_steps_per_epoch</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'Running training loop...'</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'Number of training iterations: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">num_steps</span><span class="p">))</span>

        <span class="n">step_losses</span><span class="p">,</span> <span class="n">step_scores</span><span class="p">,</span> <span class="n">eval_scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># 학습 루프를 실행함
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
            <span class="c1"># 미니배치 하나로부터 경사 하강 업데이트를 1회 수행함
</span>            <span class="n">step_loss</span><span class="p">,</span> <span class="n">step_y_true</span><span class="p">,</span> <span class="n">step_y_pred</span><span class="p">,</span> <span class="n">step_X</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_step</span><span class="p">(</span>
                <span class="n">sess</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">step_losses</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">step_loss</span><span class="p">)</span>
            <span class="c1"># 매 epoch의 말미에서, 성능 평가를 수행함
</span>            <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_steps_per_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># 학습 데이터셋으로부터 추출한 현재의 미니배치에 대하여 모델의 예측 성능을 평가함
</span>                <span class="n">step_score</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">evaluator</span><span class="p">.</span><span class="n">score</span><span class="p">(</span>
                    <span class="n">step_y_true</span><span class="p">,</span> <span class="n">step_y_pred</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="n">step_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">step_score</span><span class="p">)</span>

                <span class="c1"># 검증 데이터셋이 주어진 경우, 이를 사용하여 모델 성능을 평가함
</span>                <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">val_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="c1"># 검증 데이터셋을 사용하여 모델 성능을 평가함
</span>                    <span class="n">eval_y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span>
                        <span class="n">sess</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">val_set</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                    <span class="n">eval_score</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">evaluator</span><span class="p">.</span><span class="n">score</span><span class="p">(</span>
                        <span class="bp">self</span><span class="p">.</span><span class="n">val_set</span><span class="p">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">eval_y_pred</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                    <span class="n">eval_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">eval_score</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="c1"># 중간 결과를 출력함
</span>                        <span class="k">print</span><span class="p">(</span><span class="s">'[epoch {}]</span><span class="se">\t</span><span class="s">loss: {:.6f} |Train score: {:.6f} |Eval score: {:.6f} |lr: {:.6f}'</span>
                              <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">curr_epoch</span><span class="p">,</span> <span class="n">step_loss</span><span class="p">,</span> <span class="n">step_score</span><span class="p">,</span> <span class="n">eval_score</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">curr_learning_rate</span><span class="p">))</span>
                        <span class="c1"># 중간 결과를 플롯팅함
</span>                        <span class="n">plot_learning_curve</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">step_losses</span><span class="p">,</span> <span class="n">step_scores</span><span class="p">,</span> <span class="n">eval_scores</span><span class="o">=</span><span class="n">eval_scores</span><span class="p">,</span>
                                            <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">evaluator</span><span class="p">.</span><span class="n">mode</span><span class="p">,</span> <span class="n">img_dir</span><span class="o">=</span><span class="n">save_dir</span><span class="p">)</span>

                    <span class="n">curr_score</span> <span class="o">=</span> <span class="n">eval_score</span>
                <span class="c1"># 그렇지 않은 경우, 단순히 미니배치에 대한 결과를 사용하여 모델 성능을 평가함
</span>                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="c1"># 중간 결과를 출력함
</span>                        <span class="k">print</span><span class="p">(</span><span class="s">'[epoch {}]</span><span class="se">\t</span><span class="s">loss: {:.6f} |Train score: {:.6f} |lr: {:.6f}'</span>
                              <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">curr_epoch</span><span class="p">,</span> <span class="n">step_loss</span><span class="p">,</span> <span class="n">step_score</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">curr_learning_rate</span><span class="p">))</span>
                        <span class="c1"># 중간 결과를 플롯팅함
</span>                        <span class="n">plot_learning_curve</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">step_losses</span><span class="p">,</span> <span class="n">step_scores</span><span class="p">,</span> <span class="n">eval_scores</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                                            <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">evaluator</span><span class="p">.</span><span class="n">mode</span><span class="p">,</span> <span class="n">img_dir</span><span class="o">=</span><span class="n">save_dir</span><span class="p">)</span>

                    <span class="n">curr_score</span> <span class="o">=</span> <span class="n">step_score</span>

                <span class="c1"># 현재의 성능 점수의 현재까지의 최고 성능 점수를 비교하고,
</span>                <span class="c1"># 최고 성능 점수가 갱신된 경우 해당 성능을 발휘한 모델의 파라미터들을 저장함
</span>                <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">evaluator</span><span class="p">.</span><span class="n">is_better</span><span class="p">(</span><span class="n">curr_score</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">best_score</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">best_score</span> <span class="o">=</span> <span class="n">curr_score</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">num_bad_epochs</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">saver</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="s">'model.ckpt'</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">num_bad_epochs</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="bp">self</span><span class="p">.</span><span class="n">_update_learning_rate</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">curr_epoch</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'Total training time(sec): {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'Best {} score: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                <span class="s">'evaluation'</span> <span class="k">if</span> <span class="nb">eval</span> <span class="k">else</span> <span class="s">'training'</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">best_score</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Done.'</span><span class="p">)</span>


        <span class="k">if</span> <span class="n">details</span><span class="p">:</span>
            <span class="c1"># 학습 결과를 dict에 저장함
</span>            <span class="n">train_results</span><span class="p">[</span><span class="s">'step_losses'</span><span class="p">]</span> <span class="o">=</span> <span class="n">step_losses</span>
            <span class="n">train_results</span><span class="p">[</span><span class="s">'step_scores'</span><span class="p">]</span> <span class="o">=</span> <span class="n">step_scores</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">val_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">train_results</span><span class="p">[</span><span class="s">'eval_scores'</span><span class="p">]</span> <span class="o">=</span> <span class="n">eval_scores</span>

            <span class="k">return</span> <span class="n">train_results</span>
</code></pre></div></div>

<h4 id="momentumoptimizer-클래스">MomentumOptimizer 클래스</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MomentumOptimizer</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="s">"""모멘텀 알고리즘을 포함한 경사 하강 optimizer 클래스."""</span>

    <span class="k">def</span> <span class="nf">_optimize_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        경사 하강 업데이트를 위한 tf.train.MomentumOptimizer.minimize Op.
       :param kwargs: dict, optimizer의 추가 인자.
                -momentum: float, 모멘텀 계수.
        :return tf.Operation.
        """</span>
        <span class="n">momentum</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'momentum'</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
        <span class="n">extra_update_ops</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">GraphKeys</span><span class="p">.</span><span class="n">UPDATE_OPS</span><span class="p">)</span>
        <span class="n">update_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">extra_update_ops</span><span class="p">):</span>
            <span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">learning_rate_placeholder</span><span class="p">,</span> <span class="n">momentum</span><span class="p">).</span><span class="n">minimize</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">var_list</span><span class="o">=</span><span class="n">update_vars</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">train_op</span>

    <span class="k">def</span> <span class="nf">_update_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="s">"""
        성능 평가 점수 상에 개선이 없을 때, 현 학습률 값을 업데이트함.
        :param kwargs: dict, 학습률 스케줄링을 위한 추가 인자.
            - learning_rate_patience: int, 성능 향상이 연속적으로 이루어지지 않은 epochs 수가 
                                      해당 값을 초과할 경우, 학습률 값을 감소시킴.
            - learning_rate_decay: float, 학습률 업데이트 비율.
            - eps: float, 업데이트된 학습률 값과 기존 학습률 값 간의 차이가 해당 값보다 작을 경우,
                          학습률 업데이트를 취소함.
        """</span>
        <span class="n">learning_rate_patience</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'learning_rate_patience'</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">learning_rate_decay</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'learning_rate_decay'</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'eps'</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_bad_epochs</span> <span class="o">&gt;</span> <span class="n">learning_rate_patience</span><span class="p">:</span>
            <span class="n">new_learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">curr_learning_rate</span> <span class="o">*</span> <span class="n">learning_rate_decay</span>
            <span class="c1"># 새 학습률 값과 기존 학습률 값 간의 차이가 eps보다 큰 경우에 한해서만 업데이트를 수행함
</span>            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">curr_learning_rate</span> <span class="o">-</span> <span class="n">new_learning_rate</span> <span class="o">&gt;</span> <span class="n">eps</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">curr_learning_rate</span> <span class="o">=</span> <span class="n">new_learning_rate</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">num_bad_epochs</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Optimizer</code> 클래스에서 하는 일은 이전 Classification 문제와 거의 같기 때문에 추가로 설명은 하지 않겠습니다. 이전 포스팅의 자세한 설명을 참고해주세요! <code class="language-plaintext highlighter-rouge">MomentumOptimizer</code> 클래스 역시 거의 같지만 BatchNormalization 층을 학습하기 위하여 extra_update_ops를 추가로 정의하고 tf.control_dependecies를 이용하여 학습을 시켜줍니다. 이를 정의하지 않으면 BatchNormalization 층이 학습이 되지 않아 전체 신경망이 제대로 작동하지 않을 가능성이 큽니다. 이외에는 모두 같습니다.</p>

<h2 id="학습-수행-및-테스트-결과">학습 수행 및 테스트 결과</h2>

<p><code class="language-plaintext highlighter-rouge">train.py</code> 스크립트에서 실제 학습을 수행하는 과정을 구현하며, <code class="language-plaintext highlighter-rouge">test.py</code> 스크립트에서 테스트 데이터셋에 대해 학습이 완료된 모델을 테스트하여 성능 수치를 보여주고 실제로 바운딩 박스도 그려줍니다. 혹, 레이블이 없는 데이터셋에 대해서 그려보고 싶은 분들을 위해 <code class="language-plaintext highlighter-rouge">draw.py</code> 스크립트도 추가 구현하였으니 저장소에서 참고하시길 바랍니다.</p>

<h3 id="trainpy-스크립트">train.py 스크립트</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">""" 1. 원본 데이터셋을 메모리에 로드하고 분리함 """</span>
<span class="n">root_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">'data/face/'</span><span class="p">)</span> <span class="c1"># FIXME
</span><span class="n">trainval_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="s">'train'</span><span class="p">)</span>

<span class="c1"># 앵커 로드
</span><span class="n">anchors</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">load_json</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">trainval_dir</span><span class="p">,</span> <span class="s">'anchors.json'</span><span class="p">))</span>

<span class="c1"># 학습에 사용될 이미지 사이즈 및 클래스 개수를 정함
</span><span class="n">IM_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">416</span><span class="p">,</span> <span class="mi">416</span><span class="p">)</span>
<span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># 원본 학습+검증 데이터셋을 로드하고, 이를 학습 데이터셋과 검증 데이터셋으로 나눔
</span><span class="n">X_trainval</span><span class="p">,</span> <span class="n">y_trainval</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">read_data</span><span class="p">(</span><span class="n">trainval_dir</span><span class="p">,</span> <span class="n">IM_SIZE</span><span class="p">)</span>
<span class="n">trainval_size</span> <span class="o">=</span> <span class="n">X_trainval</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">val_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">trainval_size</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span> <span class="c1"># FIXME
</span><span class="n">val_set</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">DataSet</span><span class="p">(</span><span class="n">X_trainval</span><span class="p">[:</span><span class="n">val_size</span><span class="p">],</span> <span class="n">y_trainval</span><span class="p">[:</span><span class="n">val_size</span><span class="p">])</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">DataSet</span><span class="p">(</span><span class="n">X_trainval</span><span class="p">[</span><span class="n">val_size</span><span class="p">:],</span> <span class="n">y_trainval</span><span class="p">[</span><span class="n">val_size</span><span class="p">:])</span>

<span class="s">""" 2. 학습 수행 및 성능 평가를 위한 하이퍼파라미터 설정"""</span>
<span class="n">hp_d</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="c1"># FIXME: 학습 관련 하이퍼파라미터
</span><span class="n">hp_d</span><span class="p">[</span><span class="s">'batch_size'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hp_d</span><span class="p">[</span><span class="s">'num_epochs'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">hp_d</span><span class="p">[</span><span class="s">'init_learning_rate'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">hp_d</span><span class="p">[</span><span class="s">'momentum'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">hp_d</span><span class="p">[</span><span class="s">'learning_rate_patience'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">hp_d</span><span class="p">[</span><span class="s">'learning_rate_decay'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">hp_d</span><span class="p">[</span><span class="s">'eps'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-8</span>
<span class="n">hp_d</span><span class="p">[</span><span class="s">'score_threshold'</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">hp_d</span><span class="p">[</span><span class="s">'nms_flag'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

<span class="s">""" 3. Graph 생성, session 초기화 및 학습 시작 """</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_default_graph</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">ConfigProto</span><span class="p">()</span>
<span class="n">config</span><span class="p">.</span><span class="n">gpu_options</span><span class="p">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ConvNet</span><span class="p">([</span><span class="n">IM_SIZE</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">IM_SIZE</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">],</span> <span class="n">NUM_CLASSES</span><span class="p">,</span> <span class="n">anchors</span><span class="p">,</span> <span class="n">grid_size</span><span class="o">=</span><span class="p">(</span><span class="n">IM_SIZE</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="mi">32</span><span class="p">,</span> <span class="n">IM_SIZE</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">32</span><span class="p">))</span>

<span class="n">evaluator</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Optimizer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">evaluator</span><span class="p">,</span> <span class="n">val_set</span><span class="o">=</span><span class="n">val_set</span><span class="p">,</span> <span class="o">**</span><span class="n">hp_d</span><span class="p">)</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">graph</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">details</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">hp_d</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">train.py</code> 스크립트에서는 마찬가지로 3단계로 진행됩니다.</p>

<ol>
  <li>원본 학습 데이터셋을 메모리에 로드하고, 이를 학습 데이터셋(90%)과 검증 데이터셋(10%)으로 나눠 객체 생성.</li>
  <li>학습 관련 하이퍼파라미터 설정.</li>
  <li><code class="language-plaintext highlighter-rouge">ConvNet</code> 객체, <code class="language-plaintext highlighter-rouge">Evaluator</code> 객체 및 <code class="language-plaintext highlighter-rouge">Optimizer</code> 객체를 생성하고, TensorFlow Graph와 Session을 초기화한 뒤, <code class="language-plaintext highlighter-rouge">Optimizer.train</code> 함수를 호출하여 모델 학습을 수행함</li>
</ol>

<ul>
  <li>원본 데이터셋 저장 경로, 하이퍼파라미터 등 <code class="language-plaintext highlighter-rouge">FIXME</code>로 표시된 부분은 여러분의 상황에 맞게 수정하시면 됩니다.</li>
</ul>

<h3 id="testpy-스크립트">test.py 스크립트</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">""" 1. 원본 데이터셋을 메모리에 로드함 """</span>
<span class="n">root_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="s">'data/face'</span><span class="p">)</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="s">'test'</span><span class="p">)</span>
<span class="n">IM_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">416</span><span class="p">,</span> <span class="mi">416</span><span class="p">)</span>
<span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># 테스트 데이터셋을 로드함
</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">read_data</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span> <span class="n">IM_SIZE</span><span class="p">)</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">DataSet</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="s">""" 2. 테스트를 위한 하이퍼파라미터 설정 """</span>
<span class="n">anchors</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">load_json</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span> <span class="s">'anchors.json'</span><span class="p">))</span>
<span class="n">class_map</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">load_json</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span> <span class="s">'classes.json'</span><span class="p">))</span>
<span class="n">nms_flag</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">hp_d</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="c1"># FIXME
</span><span class="n">hp_d</span><span class="p">[</span><span class="s">'batch_size'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">hp_d</span><span class="p">[</span><span class="s">'nms_flag'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nms_flag</span>

<span class="s">""" 3. Graph 생성, 파라미터 로드, session 초기화 및 테스트 시작 """</span>
<span class="c1"># 초기화
</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_default_graph</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">ConfigProto</span><span class="p">()</span>
<span class="n">config</span><span class="p">.</span><span class="n">gpu_options</span><span class="p">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ConvNet</span><span class="p">([</span><span class="n">IM_SIZE</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">IM_SIZE</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">],</span> <span class="n">NUM_CLASSES</span><span class="p">,</span> <span class="n">anchors</span><span class="p">,</span> <span class="n">grid_size</span><span class="o">=</span><span class="p">(</span><span class="n">IM_SIZE</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="mi">32</span><span class="p">,</span> <span class="n">IM_SIZE</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">32</span><span class="p">))</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">Evaluator</span><span class="p">()</span>
<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">Saver</span><span class="p">()</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">graph</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">saver</span><span class="p">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s">'/tmp/model.ckpt'</span><span class="p">)</span>
<span class="n">test_y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="o">**</span><span class="n">hp_d</span><span class="p">)</span>
<span class="n">test_score</span> <span class="o">=</span> <span class="n">evaluator</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_set</span><span class="p">.</span><span class="n">labels</span><span class="p">,</span> <span class="n">test_y_pred</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Test performance: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">test_score</span><span class="p">))</span>

<span class="s">""" 4. 이미지에 바운딩 박스 그리기 시작 """</span>
<span class="n">draw_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span> <span class="s">'draws'</span><span class="p">)</span> <span class="c1"># FIXME
</span><span class="n">im_dir</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span> <span class="s">'images'</span><span class="p">)</span> <span class="c1"># FIXME
</span><span class="n">im_paths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">im_paths</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">glob</span><span class="p">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">im_dir</span><span class="p">,</span> <span class="s">'*.jpg'</span><span class="p">)))</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">im_path</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">test_set</span><span class="p">.</span><span class="n">images</span><span class="p">,</span> <span class="n">test_y_pred</span><span class="p">,</span> <span class="n">im_paths</span><span class="p">)):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">im_path</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">draw_path</span> <span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">draw_dir</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">nms_flag</span><span class="p">:</span>
        <span class="n">bboxes</span> <span class="o">=</span> <span class="n">predict_nms_boxes</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">conf_thres</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">iou_thres</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">bboxes</span> <span class="o">=</span> <span class="n">convert_boxes</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">bboxes</span> <span class="o">=</span> <span class="n">bboxes</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">any</span><span class="p">(</span><span class="n">bboxes</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))]</span>
    <span class="n">boxed_img</span> <span class="o">=</span> <span class="n">draw_pred_boxes</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">bboxes</span><span class="p">,</span> <span class="n">class_map</span><span class="p">)</span>
    <span class="n">cv2</span><span class="p">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">draw_path</span><span class="p">,</span> <span class="n">boxed_img</span><span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">test.py</code> 스크립트도 비슷하게 4단계 과정을 거쳐 성능을 측정하고 이미지에 예측된 오브젝트 바운딩 박스를 그려줍니다.</p>

<h2 id="학습-결과-분석">학습 결과 분석</h2>

<h3 id="학습-곡선">학습 곡선</h3>

<p>Classification 문제때와 마찬가지로 학습 수행 과정동안 학습 곡선을 그려보았습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://localhost:4000/assets/images/image-detection-deep-learning/plot.png" target="_blank">
  <img class="large-image" src="http://localhost:4000/assets/images/image-detection-deep-learning/plot.png" alt="학습 곡선 플롯팅 결과" />
</a>
<span class="caption">학습 곡선 플롯팅 결과</span></p>

<p>경험상으로 YOLO는 특별한 학습 정책을 주지않고 위의 방법대로 학습을 하는 경우, 배치사이즈가 어느정도 작을 때 더 학습이 잘 되는 것을 확인하여 학습 배치사이즈를 작게 가져가다보니 진동의 폭이 상대적으로 커 결과가 조금 알아보기 힘듭니다. 이에 편의상 재현율은 검증용 데이터셋에 대해만 표시하였습니다. 재현율 성능은 약 10 epoch 이후에 어느정도 수렴하기에, 이를 기반으로 최고 성능 모델을 저장하였습니다.</p>

<h3 id="테스트-결과">테스트 결과</h3>

<p>테스트 결과 측정된 재현율(Recall)값은 <strong>0.8734</strong>로 꽤 높은 값을 가졌습니다. 하지만 재현율 값의 경우, 얼굴이 아닌 다른 곳을 얼굴이라고 예측해도 값에 지장을 주지 않기 때문에, 엄밀한 성능 지표라고 할 수 없습니다. 이후에 실험을 하실 때 mAP, F1 score, IOU 등 상황에 맞는 성능 지표를 만들어 학습을 진행하시면 보다 좋은 성능을 가지는 모델을 얻을 수 있습니다. 다시 돌아와서, 재현율 값만 가지고 모델이 정말 잘 예측하는 지 신뢰하기 힘들기 때문에 실제 테스트 이미지에서 정말 얼굴을 잘 인식했는지 예측된 바운딩 박스를 그려 눈으로 확인해보았습니다.</p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://localhost:4000/assets/images/image-detection-deep-learning/correct.png" target="_blank">
  <img class="full-image" src="http://localhost:4000/assets/images/image-detection-deep-learning/correct.png" alt="맞게 예측한 얼굴 인식 결과 예시" />
</a>
<span class="caption">맞게 예측한 얼굴 인식 결과 예시</span></p>

<!-- @reference: https://www.kevinmcgillivray.net/captions-for-images-with-jekyll/ -->
<p><a href="http://localhost:4000/assets/images/image-detection-deep-learning/incorrect.png" target="_blank">
  <img class="full-image" src="http://localhost:4000/assets/images/image-detection-deep-learning/incorrect.png" alt="잘못 예측한 얼굴 인식 결과 예시" />
</a>
<span class="caption">잘못 예측한 얼굴 인식 결과 예시</span></p>

<p>위의 결과 처럼 대부분 얼굴 부분을 잘 예측하지만, 손이나 얼굴의 일부 등을 얼굴로 예측하는 경우도 빈번하게 있었습니다. 이런 결과나온 이유 중에 하나로 실제 훈련데이터셋에서 확인해보면 얼굴의 형체가 거의 파악되지 않는 경우도 모두 annotation이 있어 그렇지 않나 조심스럽게 판단해봅니다. 하지만 대부분 꽤 잘 예측했기에 실용적으로도 사용할 수 있지 않을까 생각합니다!</p>

<h2 id="결론">결론</h2>

<p>본 포스팅에서는 이미지 인식 분야에서 중요하게 다뤄지는 Detection 문제를 응용할 수 있는 <strong>얼굴 인식</strong>  사례를 소개하고 이를 YOLO 모델과 TensorFlow를 이용한 딥러닝 알고리즘으로 해결하는 과정을 간단하게 안내해드렸습니다. 미흡한 점이 많이 보이나, 실제 Detection 문제를 공부하고 처음 구현해보시는 분들에게 어느정도 도움이 되기를 바랍니다.</p>

<p>**추후 글은 이미지 인식 분야 3가지 중 마지막 Segmentation에 대해 마찬가지로 예시 문제와 모델을 선정하여 해결하는 과정을 소개해드리겠습니다.</p>

<h2 id="references">References</h2>

<ul>
  <li>YOLO 논문
    <ul>
      <li><a href="https://arxiv.org/pdf/1612.08242.pdf" target="_blank">YOLO9000: Better, Faster, Stronger</a></li>
    </ul>
  </li>
  <li>FDDB dataset
    <ul>
      <li><a href="http://vis-www.cs.umass.edu/fddb/samples/" target="_blank">FDDB: Face Detection Data Set and Benchmark</a></li>
    </ul>
  </li>
</ul>

  </div>

</article>

      </div>
    </main><footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Cognex Deep Learning Lab-KOR Research Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Cognex Deep Learning Lab-KOR Research Blog
            
            </li>
            
            <li><a href="https://www.cognex.co.kr/" target="_blank">https://www.cognex.co.kr/</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          

          
          
          <li>
            <a href="https://facebook.com/cognexcorp" target="_blank"><i class="fa fa-facebook"></i> <span class="username">cognexcorp</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Cognex Deep Learning Lab-KOR research blog: covers subjects regarding machine learning, computer vision, high-performance computing, and so on.
</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
